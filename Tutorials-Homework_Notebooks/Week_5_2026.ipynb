{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KnowledgeLab/Thinking-With-Deep-Learning-2026/blob/main/Tutorials-Homework_Notebooks/Week%205/Week_5_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header_main"
   },
   "source": [
    "#**Thinking with Deep Learning: Week 5 Homework Modules**\n",
    "\n",
    "## Sampling, Fine Tuning, Benchmarking, and Tools\n",
    "\n",
    "- __Instructor:__ James Evans\n",
    "\n",
    "- __Notebook Author & TAs:__ Avi, Gio, Jesse, Shiyang \n",
    "\n",
    "This week we explore the potential for data-driven bias in social scientific inference with AI agents, and how to fine-tune large transformer-based agents to limit bias or adopt specific perspectives.\n",
    "\n",
    "__Perform 3 out of this week's following 4 modules:__\n",
    "\n",
    "##1. [**Sampling**](#module1)\n",
    "### **Summary:**\n",
    "Sampling is a critical method for data science and AI. In this section we review probabilistic and non-probabilistic sampling techniques, handling imbalanced datasets, and bootstrap sampling for testing embedding stability.\n",
    "\n",
    "### **Tasks/Questions:**\n",
    "**1)** Run 3 probabilistic sampling methods and 2 non-probabilistic methods and explore the samples returned.\n",
    "\n",
    "**2)** Find an imbalanced dataset and build a classifier to predict the label causing the imbalance. Explore undersampling and oversampling solutions.\n",
    "\n",
    "**3)** Use bootstrap sampling to test the stability of a word, sentence, or graph embedding.\n",
    "\n",
    "##2. [**Fine-Tuning with LoRA and QLoRA**](#module2)\n",
    "### **Summary:**\n",
    "Fine-tuning neural networks involves taking a pre-trained model and adjusting its parameters for a specific task. We focus on Low-Rank Adaptation (LoRA) and Quantized LoRA (QLoRA) for efficient fine-tuning of large language models.\n",
    "\n",
    "### **Tasks/Questions:**\n",
    "**1)** Fine-tune a small LLM (e.g., GPT-2) using LoRA on a text dataset of your choice.\n",
    "\n",
    "**2)** Compare the number of trainable parameters between full fine-tuning and LoRA.\n",
    "\n",
    "**3)** Experiment with different LoRA rank values (r=4, 8, 16) and observe the impact on performance.\n",
    "\n",
    "##3. [**Benchmarking LLM Agents**](#module3)\n",
    "### **Summary:**\n",
    "Evaluating LLM-based agents requires systematic benchmarking approaches. We explore Centered Kernel Alignment (CKA) for comparing neural representations and discuss frameworks for evaluating agent capabilities, safety, and performance.\n",
    "\n",
    "### **Tasks/Questions:**\n",
    "**1)** Implement CKA to compare representations between two different models or layers.\n",
    "\n",
    "**2)** Design a simple benchmark task for an LLM agent and evaluate its performance.\n",
    "\n",
    "**3)** Discuss potential biases in benchmark design and how they might affect evaluation results.\n",
    "\n",
    "##4. [**Tools and the Model Context Protocol (MCP)**](#module4)\n",
    "### **Summary:**\n",
    "Modern LLM agents interact with external tools and data sources. The Model Context Protocol (MCP) provides a standardized way for AI models to access context from various sources. We explore tool use patterns and MCP implementation.\n",
    "\n",
    "### **Tasks/Questions:**\n",
    "**1)** Implement a simple tool-using agent that can call external functions.\n",
    "\n",
    "**2)** Create an MCP server that exposes a data source to an LLM.\n",
    "\n",
    "**3)** Discuss the implications of tool use for AI agent safety and capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "module_checkboxes"
   },
   "outputs": [],
   "source": [
    "# @markdown Mark the Modules you completed\n",
    "Sampling = False  # @param {type:\"boolean\"}\n",
    "FineTuning_LoRA = False  # @param {type:\"boolean\"}\n",
    "Benchmarking_LLM_Agents = False  # @param {type:\"boolean\"}\n",
    "Tools_and_MCP = False  # @param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "module1"
   },
   "source": [
    "# Module 1: Sampling\n",
    "\n",
    "\n",
    "[Sampling](https://en.wikipedia.org/wiki/Sampling_(statistics)) is a critical method which you've likely come across in previous data or social science explorations. In this section we will review several of the more popular techniques used in research and industry. There is no one standard package for sampling with python, and we will be using the rich PyData ecosystem in different ways to achieve our aims.\n",
    "\n",
    "Here are some links you may wish to explore:\n",
    "\n",
    "- Krippendorff, Klaus. 2004. Content Analysis: An Introduction to its Methodology. Thousand Oaks, CA: Sage: [\u201cSampling\u201d](https://canvas.uchicago.edu/courses/33672/files/4767016/download?wrap=1)(for sampling content).\n",
    "- [Data Scientist's guide to 8 sampling techniques](https://www.analyticsvidhya.com/blog/2019/09/data-scientists-guide-8-types-of-sampling-techniques/\n",
    ")\n",
    "- [KDnuggets - 5 sampling algorithms](https://www.kdnuggets.com/2019/09/5-sampling-algorithms.html)\n",
    "\n",
    "Sampling procedures are often divided into probabilistic and non-probabilistic methods, and we begin with the same division before jumping into methods tuned for maximizing machine and deep learning model generalizability.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "module1_setup"
   },
   "source": [
    "# Module 1 Setup: Install required packages and download data\n",
    "# Note: We install packages carefully to avoid pandas version conflicts in Colab\n",
    "\n",
    "!pip install scikit-learn imbalanced-learn gensim yellowbrick gdown -q\n",
    "!pip install littleballoffur --no-deps -q  # Install without dependencies to avoid pandas downgrade\n",
    "!pip install networkx scipy decorator -q   # Install littleballoffur's actual dependencies\n",
    "\n",
    "# Download the mental health dataset from Google Drive\n",
    "import gdown\n",
    "gdown.download('https://drive.google.com/uc?id=1-0r2C4z9-vAedJ4uum-TfI4Zy4gKDGaQ', '/content/mental health.csv', quiet=False)\n",
    "\n",
    "print('Module 1 setup complete!')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxII-UadWars"
   },
   "source": [
    "## Probabilistic Sampling\n",
    "\n",
    "Often we hear about sampling from a probability distribution, but such methods typically extend to sampling from real world data. For the examples in this section, we use both a real dataset and randomly constructed distributions, both of which are useful tools. The power of these methods in the context of machine and deep learning (and its human and social uses!) will become clear.  \n",
    "\n",
    "### Dataset\n",
    "\n",
    "One of the datasets we will be using is the \"Mental Health in Tech Survey\" data, an open source survey data about mental health conditions of workers in tech industries. We also worked with this data for the week 5 hint. You can find the data at Kaggle:\n",
    "\n",
    "https://www.kaggle.com/osmi/mental-health-in-tech-survey\n",
    "\n",
    "[google drive link of cleaned data](https://drive.google.com/file/d/1-0r2C4z9-vAedJ4uum-TfI4Zy4gKDGaQ/view?usp=sharing)\n",
    "\n",
    "We provided a cleaned version. The predictors contain 1 continuous variable (age), 3 dummies (Do you work remotely? Is your employer primarily a tech company? Does your employer provide any mental health benefits?) and 2 categorical variables (gender-male/female/other; can you discuss your mental health issue with supervisors-yes/sometimes/no).\n",
    "\n",
    "The outcome is an answer to the question: If you have a mental health condition, do you feel it interferes with your work? The DV is measured with a 5-categorical variable: NA (no mental health condition), never, rarely, sometimes, often.\n",
    "\n",
    "**An important note**: very often we are sampling from a very large dataset or population - in this case, our dataset is small enough that we can analyze the whole dataset (which itself represents a sample of the tech population), and the sampling is purely illustratory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErnTXsaBWars"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zX5qEf3uWart"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/mental health.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGiK1rhEWart",
    "outputId": "570dd2f4-1f78-494d-9691-70397b69551f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-623cb265-37e3-499b-a65f-225024d2e6a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>some of them</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows \u00d7 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-623cb265-37e3-499b-a65f-225024d2e6a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-623cb265-37e3-499b-a65f-225024d2e6a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-623cb265-37e3-499b-a65f-225024d2e6a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech  gender    supervisor  interfere\n",
       "0       8       1         1     1   other           yes          4\n",
       "1      21       0         0     1   other  some of them          3\n",
       "2      32       0         0     1   other            no          4\n",
       "3      28       0         0     1   other  some of them          2\n",
       "4      27       1         1     1   other           yes          4\n",
       "...   ...     ...       ...   ...     ...           ...        ...\n",
       "1254   32       1         1     1   other           yes          4\n",
       "1255   26       1         0     1   other  some of them          3\n",
       "1256   30       0         1     1   other           yes          2\n",
       "1257   18       1         1     1   other           yes          0\n",
       "1258   34       0         1     0  female  some of them          2\n",
       "\n",
       "[1259 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wP45kLSWart"
   },
   "source": [
    "### Random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m70XV8gdWart"
   },
   "outputs": [],
   "source": [
    "sample_df = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOycQ-T_Waru",
    "outputId": "47131695-74a1-4106-9b1c-2d964acb0c9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2fbf9e05-18d8-4bfe-b303-89c3791c13e6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows \u00d7 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fbf9e05-18d8-4bfe-b303-89c3791c13e6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2fbf9e05-18d8-4bfe-b303-89c3791c13e6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2fbf9e05-18d8-4bfe-b303-89c3791c13e6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech gender supervisor  interfere\n",
       "1237   37       0         1     1   male        yes          3\n",
       "1010   44       1         0     0   male         no          0\n",
       "676    27       0         0     1   male         no          0\n",
       "1202   35       1         0     0   male         no          3\n",
       "1234   40       0         0     1   male        yes          3\n",
       "...   ...     ...       ...   ...    ...        ...        ...\n",
       "1209   34       1         0     1   male        yes          0\n",
       "492    50       1         0     1   male        yes          1\n",
       "853    25       0         0     1   male        yes          0\n",
       "190    33       1         0     1   male        yes          3\n",
       "700    33       0         1     0   male         no          3\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNB_anyWWaru"
   },
   "source": [
    "[SciPy](https://docs.scipy.org/doc/numpy-1.10.1/reference/routines.random.html) and [numpy](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) also offer many popular sampling techniques, usually to be applied on a list or array, or sampled from a distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X2bJLN7Waru"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ar3UIGQ0Waru"
   },
   "outputs": [],
   "source": [
    "random_vals = np.random.rand(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwydTc1lWaru",
    "outputId": "c495846a-a731-4f9a-830c-ac240e03d127"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.87756341, 0.08953556, 0.22070822, 0.13464803, 0.77722257,\n",
       "       0.28488422, 0.56600295, 0.22611083, 0.48242142, 0.4443197 ,\n",
       "       0.98419314, 0.96476736, 0.79155608, 0.37454349, 0.18619156,\n",
       "       0.67029591, 0.40881112, 0.03007655, 0.8814407 , 0.61269684,\n",
       "       0.14286068, 0.35440079, 0.58676128, 0.99899733, 0.96259004,\n",
       "       0.0755457 , 0.36263351, 0.11824383, 0.9028245 , 0.18863398,\n",
       "       0.34411585, 0.83408633, 0.42978301, 0.67239463, 0.4870574 ,\n",
       "       0.87684776, 0.3114396 , 0.96132891, 0.41435173, 0.63550723,\n",
       "       0.60379586, 0.97713603, 0.07941813, 0.12634668, 0.03684195,\n",
       "       0.51592944, 0.04105821, 0.72068143, 0.49918895, 0.67089092,\n",
       "       0.04196314, 0.05935925, 0.39744373, 0.20719472, 0.27868948,\n",
       "       0.88444396, 0.52586205, 0.02107223, 0.33888305, 0.01135199,\n",
       "       0.1468008 , 0.68537626, 0.30995161, 0.26176913, 0.85267301,\n",
       "       0.92495817, 0.25419009, 0.60623648, 0.39284497, 0.88388632,\n",
       "       0.44423055, 0.17403786, 0.46351792, 0.127054  , 0.52500133,\n",
       "       0.54166615, 0.34686102, 0.06401155, 0.66900111, 0.18907974,\n",
       "       0.86751612, 0.14147891, 0.73114849, 0.98054787, 0.04188433,\n",
       "       0.76548194, 0.24668704, 0.51952609, 0.59558686, 0.99136714,\n",
       "       0.01322196, 0.08118653, 0.9451901 , 0.38050779, 0.21251054,\n",
       "       0.29079387, 0.3412471 , 0.43570898, 0.78865663, 0.21038356,\n",
       "       0.76743572, 0.13261461, 0.7091014 , 0.3655007 , 0.20388955,\n",
       "       0.43548568, 0.0229568 , 0.976312  , 0.76255845, 0.04165767,\n",
       "       0.76950344, 0.60242518, 0.88889878, 0.75844305, 0.89759565,\n",
       "       0.53747149, 0.52917918, 0.24291913, 0.23170714, 0.92775541,\n",
       "       0.04615236, 0.44547188, 0.30269374, 0.27413227, 0.43721526,\n",
       "       0.13826028, 0.91600909, 0.20478653, 0.55047092, 0.66663182,\n",
       "       0.42155044, 0.10030323, 0.68723788, 0.09019338, 0.5052159 ,\n",
       "       0.57990798, 0.53046729, 0.82306982, 0.54935442, 0.15077188,\n",
       "       0.90195269, 0.48631301, 0.64198914, 0.67605156, 0.38072796,\n",
       "       0.05360291, 0.60568615, 0.49872973, 0.74191414, 0.80853955,\n",
       "       0.0288506 , 0.08496467, 0.71000923, 0.50275969, 0.32768195,\n",
       "       0.97607187, 0.09386274, 0.7741712 , 0.13616924, 0.22373975,\n",
       "       0.66600095, 0.38589331, 0.94882266, 0.36667541, 0.31315534,\n",
       "       0.93998759, 0.51387847, 0.67339023, 0.01224771, 0.46439611,\n",
       "       0.70490651, 0.69277586, 0.40661526, 0.74119197, 0.71142532,\n",
       "       0.38132902, 0.11009168, 0.96795362, 0.21386459, 0.73613006,\n",
       "       0.77142814, 0.86564232, 0.87457393, 0.78552503, 0.32504312,\n",
       "       0.21816754, 0.65622222, 0.51081065, 0.27976548, 0.48399873,\n",
       "       0.4203135 , 0.53779477, 0.40325192, 0.79446711, 0.99370881,\n",
       "       0.13988785, 0.56709967, 0.26881666, 0.03405451, 0.88235484,\n",
       "       0.64356218, 0.7783952 , 0.6825519 , 0.89660451, 0.17989228,\n",
       "       0.37186274, 0.6234273 , 0.84956533, 0.21426584, 0.17896038,\n",
       "       0.30332193, 0.02568679, 0.25000076, 0.07375734, 0.42296733,\n",
       "       0.14415753, 0.57338762, 0.77673085, 0.32805755, 0.24031638,\n",
       "       0.40852381, 0.32004116, 0.82624151, 0.12095826, 0.71846003,\n",
       "       0.29052584, 0.897157  , 0.85786739, 0.64212641, 0.21395688,\n",
       "       0.50024456, 0.84959492, 0.45786663, 0.0239874 , 0.93138168,\n",
       "       0.73166186, 0.24631087, 0.67920084, 0.60076925, 0.33399063,\n",
       "       0.15561787, 0.47826178, 0.96129907, 0.40208689, 0.326423  ,\n",
       "       0.09186553, 0.06109956, 0.61568858, 0.72159108, 0.77263916,\n",
       "       0.90291143, 0.20284507, 0.103467  , 0.78622803, 0.10867638,\n",
       "       0.47881033, 0.95623589, 0.1380132 , 0.36617055, 0.05641936,\n",
       "       0.78562913, 0.32565877, 0.42995636, 0.44270567, 0.42160618,\n",
       "       0.14755019, 0.27315907, 0.16984635, 0.40183799, 0.62395962,\n",
       "       0.18216745, 0.21391638, 0.83578928, 0.30263186, 0.29288853,\n",
       "       0.90723781, 0.89595161, 0.13762778, 0.36760584, 0.07111514,\n",
       "       0.94396731, 0.37398978, 0.02088255, 0.17028269, 0.36901465,\n",
       "       0.38613319, 0.51564133, 0.13833397, 0.71975375, 0.50630065,\n",
       "       0.75808959, 0.31569863, 0.71718304, 0.39345095, 0.55963488,\n",
       "       0.33066217, 0.90080582, 0.04254314, 0.02191318, 0.06768391,\n",
       "       0.99410064, 0.09892017, 0.89510541, 0.85981101, 0.38194054,\n",
       "       0.49630851, 0.42085124, 0.18288805, 0.27780452, 0.85470795,\n",
       "       0.29838368, 0.06336348, 0.02949326, 0.80115456, 0.94171428,\n",
       "       0.87157888, 0.60947198, 0.59801566, 0.49509885, 0.40810259,\n",
       "       0.69688299, 0.22949279, 0.71697021, 0.39184292, 0.71679996,\n",
       "       0.91670726, 0.06273171, 0.08106196, 0.17803449, 0.76063882,\n",
       "       0.79434481, 0.17059966, 0.15990466, 0.86585919, 0.98283199,\n",
       "       0.71119702, 0.94082292, 0.08905693, 0.53251881, 0.88192023,\n",
       "       0.88938287, 0.0100546 , 0.05649735, 0.14474797, 0.99371336,\n",
       "       0.98904945, 0.97502846, 0.59212889, 0.97715885, 0.92944282,\n",
       "       0.81114263, 0.0240638 , 0.56844141, 0.9082497 , 0.6391894 ,\n",
       "       0.97800001, 0.76508859, 0.57756992, 0.31049772, 0.17353586,\n",
       "       0.04854188, 0.46379352, 0.20737316, 0.17906214, 0.85203798,\n",
       "       0.15423351, 0.50892868, 0.71044718, 0.00575145, 0.40556855,\n",
       "       0.88447479, 0.58739552, 0.30138046, 0.10292792, 0.25162332,\n",
       "       0.42614924, 0.70576244, 0.16546854, 0.46212212, 0.29676817,\n",
       "       0.92365863, 0.4757056 , 0.17770168, 0.53927663, 0.90727308,\n",
       "       0.26417129, 0.98330543, 0.47582658, 0.91119682, 0.10477454,\n",
       "       0.0233659 , 0.56402088, 0.86276743, 0.78975728, 0.73206808,\n",
       "       0.98567766, 0.02128625, 0.93209728, 0.03420355, 0.3825539 ,\n",
       "       0.28977424, 0.40113197, 0.04774992, 0.24046808, 0.72545671,\n",
       "       0.47665518, 0.55422153, 0.16577798, 0.07611712, 0.77742568,\n",
       "       0.68014192, 0.74216597, 0.3410978 , 0.88137817, 0.0187699 ,\n",
       "       0.28380357, 0.67954246, 0.77220974, 0.57189313, 0.77719171,\n",
       "       0.89708308, 0.44160757, 0.74753415, 0.50992124, 0.27712796,\n",
       "       0.01554798, 0.6046464 , 0.63981746, 0.55095263, 0.97625459,\n",
       "       0.02882938, 0.96996165, 0.57323857, 0.01543515, 0.59338267,\n",
       "       0.02798899, 0.51629994, 0.42092912, 0.52313552, 0.67544739,\n",
       "       0.60560108, 0.84667319, 0.08582691, 0.05812729, 0.003681  ,\n",
       "       0.13931979, 0.84251435, 0.54664414, 0.29364541, 0.52326903,\n",
       "       0.10045201, 0.77785989, 0.06123937, 0.83745433, 0.94755985,\n",
       "       0.48508723, 0.72113474, 0.20105599, 0.75436724, 0.48444069,\n",
       "       0.94873684, 0.61743285, 0.12526704, 0.2659407 , 0.80876517,\n",
       "       0.2635887 , 0.83377319, 0.46544318, 0.48899324, 0.50791443,\n",
       "       0.06493577, 0.28195829, 0.03572835, 0.61436411, 0.06119133,\n",
       "       0.913953  , 0.23559218, 0.49406364, 0.2928107 , 0.14772566,\n",
       "       0.42054128, 0.19605139, 0.36261474, 0.47606805, 0.24229584,\n",
       "       0.15295252, 0.02143383, 0.82041062, 0.75402184, 0.06341301,\n",
       "       0.54101084, 0.99380774, 0.35860168, 0.38031238, 0.07059912,\n",
       "       0.12580483, 0.82662233, 0.20756091, 0.19324387, 0.29316329])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPdOaTxQWaru",
    "outputId": "f3a367c9-170b-4fe8-dc6b-c67b067e72fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37454349, 0.33888305, 0.97607187, 0.86276743, 0.21395688,\n",
       "       0.61568858, 0.28488422, 0.86564232, 0.18907974, 0.10045201])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.choice(random_vals, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4GUWTyjWaru"
   },
   "source": [
    "In this case, we first generated an array of size 500 by randomly sampling between 0 and 1, and then sampled 10 values from this list. We can similarly sample values from any list by using the scipy and numpy random module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZUJXBadWaru"
   },
   "source": [
    "### Stratified\n",
    "\n",
    "Stratified random sampling is a method for sampling that involves the division of a population into smaller sub-groups known as strata and then sampling elements equally across those groups. In stratified random sampling, or stratification, the strata are formed based on members' shared attributes or characteristics such as age, income level, or onsite vs. remote work status. [Here](https://www.investopedia.com/terms/stratified_random_sampling.asp) is a source for reading more about it. We use stratified sampling in order to balance our dataset according to attributes of interest. Deep learning models trained to predict very rare classes, for example, may intelligently predict their absence and achieve high performance scores if we do not balance the data with respect to classes of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H88dkJN2Waru"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHUYm3wJWaru"
   },
   "outputs": [],
   "source": [
    "stratified_sample, _ = train_test_split(df, train_size=0.10, stratify=df[['remote']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euwFdcQNWarv",
    "outputId": "0002f149-af3e-48ef-cbe2-d534f560a871"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7b9196ba-1e84-4518-901f-b0769ba7f91d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>some of them</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows \u00d7 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b9196ba-1e84-4518-901f-b0769ba7f91d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7b9196ba-1e84-4518-901f-b0769ba7f91d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7b9196ba-1e84-4518-901f-b0769ba7f91d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech  gender    supervisor  interfere\n",
       "159    26       1         1     1  female            no          2\n",
       "1069   34       0         1     1    male           yes          4\n",
       "540    22       0         1     1    male           yes          0\n",
       "133    32       0         1     1  female  some of them          1\n",
       "432    25       0         0     1    male  some of them          3\n",
       "...   ...     ...       ...   ...     ...           ...        ...\n",
       "1056   34       0         1     1    male            no          3\n",
       "991    38       0         1     1  female            no          0\n",
       "720    28       0         1     1    male            no          2\n",
       "333    25       1         0     1    male           yes          0\n",
       "385    35       0         0     1    male  some of them          3\n",
       "\n",
       "[125 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stratified_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIBXTzY9Warv"
   },
   "source": [
    "In this case we get stratified results for remote work, and our remote work attribute is represented as per the original ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6N1voktWarv"
   },
   "source": [
    "### Varying probability sampling (weighted by variables of interest)\n",
    "\n",
    "We can also sample by weighting certain attributes so that our sample represents them proportional to those weights. With Pandas we can do this using a DataFrame column as weights. Rows with larger value in the column are more likely to be sampled.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lukx8dFWarv"
   },
   "outputs": [],
   "source": [
    "weight_sample = df.sample(n=125, weights='age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qT1pnQ5Warv",
    "outputId": "a834ce58-5c19-4ae1-ede2-133bd8883a4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-51f3d902-f3aa-49eb-9a20-668c28add54f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows \u00d7 7 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51f3d902-f3aa-49eb-9a20-668c28add54f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-51f3d902-f3aa-49eb-9a20-668c28add54f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-51f3d902-f3aa-49eb-9a20-668c28add54f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech gender    supervisor  interfere\n",
       "1096   32       0         0     1   male  some of them          1\n",
       "411    24       0         1     1   male           yes          2\n",
       "425    43       1         1     1   male  some of them          3\n",
       "1066   34       0         0     1   male           yes          4\n",
       "872    38       1         1     1   male  some of them          3\n",
       "...   ...     ...       ...   ...    ...           ...        ...\n",
       "389    38       0         0     1   male            no          3\n",
       "798    39       0         1     1   male  some of them          4\n",
       "1126   46       0         1     1   male            no          3\n",
       "1059   24       0         0     1   male           yes          1\n",
       "746    29       0         0     0   male           yes          4\n",
       "\n",
       "[125 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEsZWOauWarv",
    "outputId": "a1f50c80-7401-451e-da34-bbab79ba1aa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_sample['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epH20iKZWarv",
    "outputId": "879cf502-802f-4dd8-e554-f3687e1f3af0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.01906274821287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86fwQR9UWarv"
   },
   "source": [
    "Because we weighted by age, older ages are prioritised, which leads to that small bump in the mean age of the weighted sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScklALL8Warv"
   },
   "source": [
    "### Cluster Sampling (lists of large groups of units)\n",
    "\n",
    "In cluster sampling, the sampling unit is the whole cluster; Instead of sampling individuals from within each group, a researcher will study whole clusters.\n",
    "\n",
    "The difference between cluster and stratified sampling is that with cluster sampling, you have natural groups separating your population. For example, you might be able to divide your data into natural groupings like city blocks, voting districts or school districts.\n",
    "\n",
    "In short, the population is divided into subsets or subgroups that are considered as clusters, and from the numbers of clusters, we select the individual cluster for the next step to be performed.\n",
    "\n",
    "You can read more about cluster sampling [here](https://www.geeksforgeeks.org/cluster-sampling-in-pandas/).\n",
    "\n",
    "There are a couple of ways to do cluster sampling - one way is to meaningfully partition or cluster the dataset, and then choose that whole cluster as your sample. In this case, we will cluster based on age and then choose samples from one of these clusters. For some purposes (e.g., musical tastes), age would be poor variable on which to sample, naturally creating clustered results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2F9wVMOWarv"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwJ6ka9IWarv"
   },
   "outputs": [],
   "source": [
    "age_cluster = KMeans(n_clusters=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmDc2w9HWarv",
    "outputId": "520847fd-100e-47d3-dd2a-d57f3262bd7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_cluster.fit(np.array(df['age']).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqu7VREgWarv"
   },
   "outputs": [],
   "source": [
    "df['cluster'] = age_cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOoQeDSLWarv",
    "outputId": "245a177f-c1ab-4985-c94b-b9b3d23caf1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e5f0b186-4776-4987-84de-c353cc79a588\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>some of them</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1259 rows \u00d7 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5f0b186-4776-4987-84de-c353cc79a588')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e5f0b186-4776-4987-84de-c353cc79a588 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e5f0b186-4776-4987-84de-c353cc79a588');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech  gender    supervisor  interfere  cluster\n",
       "0       8       1         1     1   other           yes          4       11\n",
       "1      21       0         0     1   other  some of them          3        7\n",
       "2      32       0         0     1   other            no          4        9\n",
       "3      28       0         0     1   other  some of them          2        5\n",
       "4      27       1         1     1   other           yes          4        5\n",
       "...   ...     ...       ...   ...     ...           ...        ...      ...\n",
       "1254   32       1         1     1   other           yes          4        9\n",
       "1255   26       1         0     1   other  some of them          3        5\n",
       "1256   30       0         1     1   other           yes          2        0\n",
       "1257   18       1         1     1   other           yes          0        7\n",
       "1258   34       0         1     0  female  some of them          2        4\n",
       "\n",
       "[1259 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KORpGc4VWarv",
    "outputId": "08a391c2-695d-46a1-aebf-4bc9ebf4ec2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f1001035-66a8-45e4-8c73-c45486f329a5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1001035-66a8-45e4-8c73-c45486f329a5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f1001035-66a8-45e4-8c73-c45486f329a5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f1001035-66a8-45e4-8c73-c45486f329a5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech  gender    supervisor  interfere  cluster\n",
       "15     47       1         0     1  female            no          0        3\n",
       "171    48       0         0     1   other  some of them          4        3\n",
       "208    50       0         1     1    male           yes          0        3\n",
       "224    47       0         1     1    male           yes          3        3\n",
       "229    48       0         0     1    male            no          1        3\n",
       "244    48       0         0     1    male            no          0        3\n",
       "263    51       1         0     1    male            no          1        3\n",
       "435    51       1         0     1    male            no          3        3\n",
       "476    51       1         1     1    male           yes          1        3\n",
       "492    50       1         0     1    male           yes          1        3\n",
       "493    50       1         0     1    male           yes          0        3\n",
       "557    49       0         1     1    male           yes          1        3\n",
       "574    53       1         1     1    male            no          2        3\n",
       "597    50       1         0     1    male            no          1        3\n",
       "610    50       1         0     1    male  some of them          3        3\n",
       "749    48       0         1     0    male           yes          1        3\n",
       "795    49       0         1     1    male            no          3        3\n",
       "800    48       0         1     1    male           yes          1        3\n",
       "901    49       0         1     1    male           yes          3        3\n",
       "1020   51       0         0     1    male  some of them          1        3\n",
       "1037   51       0         0     0    male           yes          0        3\n",
       "1073   49       1         0     1    male            no          3        3\n",
       "1091   48       0         0     1    male            no          3        3\n",
       "1121   50       1         0     1    male           yes          3        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df['cluster'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBLIhsOOWarv",
    "outputId": "13e328f0-51f8-4b02-d1f1-2542e605a51b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0566578c-9211-4401-a2f1-f17fff92fbef\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>some of them</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0566578c-9211-4401-a2f1-f17fff92fbef')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0566578c-9211-4401-a2f1-f17fff92fbef button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0566578c-9211-4401-a2f1-f17fff92fbef');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech  gender    supervisor  interfere  cluster\n",
       "171    48       0         0     1   other  some of them          4        3\n",
       "557    49       0         1     1    male           yes          1        3\n",
       "15     47       1         0     1  female            no          0        3\n",
       "208    50       0         1     1    male           yes          0        3\n",
       "229    48       0         0     1    male            no          1        3\n",
       "1073   49       1         0     1    male            no          3        3\n",
       "224    47       0         1     1    male           yes          3        3\n",
       "1020   51       0         0     1    male  some of them          1        3\n",
       "1121   50       1         0     1    male           yes          3        3\n",
       "435    51       1         0     1    male            no          3        3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df['cluster'] == 3].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XEukzaaGWarv"
   },
   "source": [
    "### Systematic\n",
    "\n",
    "Systematic Sampling is defined as a type of Probability Sampling where a researcher can select targeted data from large set of data. Targeted data is chosen by selecting random starting points and from those adding others following a certain interval (e.g., randomly selecting Thursday papers from the *New York Times*). In this way a small subset (sample) is extracted from large data.\n",
    "\n",
    "You can read more about systematic sampling [here](https://www.geeksforgeeks.org/systematic-sampling-in-pandas/).\n",
    "\n",
    "For an example using our current dataset, suppose we sample from only those who work remotely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrXal0ZoWarv"
   },
   "outputs": [],
   "source": [
    "remote_sample = df[df['remote'] == 1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxCTpDrZWarv",
    "outputId": "d524b5ec-8521-4e7c-d1e1-5ba2757e429a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6e5e3545-ab29-4c64-afa4-7fb5c78f01be\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>remote</th>\n",
       "      <th>benefits</th>\n",
       "      <th>tech</th>\n",
       "      <th>gender</th>\n",
       "      <th>supervisor</th>\n",
       "      <th>interfere</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>some of them</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e5e3545-ab29-4c64-afa4-7fb5c78f01be')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6e5e3545-ab29-4c64-afa4-7fb5c78f01be button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6e5e3545-ab29-4c64-afa4-7fb5c78f01be');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      age  remote  benefits  tech gender    supervisor  interfere  cluster\n",
       "313    27       1         0     1   male  some of them          3        5\n",
       "806    38       1         0     1   male           yes          0        1\n",
       "4      27       1         1     1  other           yes          4        5\n",
       "401    30       1         0     1   male  some of them          1        0\n",
       "813    33       1         0     1   male           yes          4        9\n",
       "1161   18       1         0     0   male            no          0        7\n",
       "533    35       1         0     1   male            no          0        4\n",
       "1057   33       1         0     1   male            no          4        9\n",
       "259    40       1         1     1   male            no          3        1\n",
       "816    33       1         0     1   male            no          2        9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "remote_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZmTquENWarv"
   },
   "source": [
    "### Graph Sampling\n",
    "\n",
    "Sometimes we come across social data that must be sampled as a graph to retain its integrity. In this section we will explore some ways of sampling from graphs to minimize poor prediction (and biased inferences). To illustrate these examples, we will sample from a graph-based dataset. It is possible to extend these methods to your data that might not be (at first) represented in a graph-like way by restructuring your data in a way that supports these methods (e.g., recall that structured data can be interpreted as an adjacency matrix).\n",
    "\n",
    "We will use a python package we briefly touched upon earlier, [Little Ball of Fur](https://arxiv.org/pdf/2006.04311.pdf).\n",
    "\n",
    "#### Data\n",
    "\n",
    "We will use a dataset based on GitHub data. In this graph nodes represent GitHub developers and edges between them are mutual follower relationships. For details about the dataset see this [paper](https://arxiv.org/abs/1909.13021Z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgNV9s8qWarv",
    "outputId": "c8f0c092-1525-4537-b343-c3088cd555c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting littleballoffur\n",
      "  Downloading littleballoffur-2.1.12.tar.gz (20 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (4.4.2)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (3.12.0)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (0.29.28)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (2.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (4.64.0)\n",
      "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (0.16)\n",
      "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (1.3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (1.21.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (1.15.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from littleballoffur) (1.4.1)\n",
      "Collecting networkit==7.1\n",
      "  Downloading networkit-7.1.tar.gz (3.1 MB)\n",
      "\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.1 MB 34.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->littleballoffur) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->littleballoffur) (2.8.2)\n",
      "Building wheels for collected packages: littleballoffur, networkit\n",
      "  Building wheel for littleballoffur (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for littleballoffur: filename=littleballoffur-2.1.12-py3-none-any.whl size=40409 sha256=6d1ed8a787d016a21166a60a9749189886b0af069650e8162c12180e3e3d70a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/ba/f8/f66537badaf1e475ec56de5af58ce294bbb0fbe570ca888f8e\n",
      "  Building wheel for networkit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for networkit: filename=networkit-7.1-cp37-cp37m-linux_x86_64.whl size=8049002 sha256=abfced58b80726af2f5b00ccd261ca0550b63849d446b777f73c2363f1b18a83\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/8f/06/512044bbf7240e78fc054b506e075f0871c7642bec400a2647\n",
      "Successfully built littleballoffur networkit\n",
      "Installing collected packages: networkit, littleballoffur\n",
      "Successfully installed littleballoffur-2.1.12 networkit-7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install littleballoffur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RoS4Vl1War3",
    "outputId": "37e0cf6e-672e-4c68-bb6a-759720acbe8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from littleballoffur import GraphReader\n",
    "\n",
    "reader = GraphReader(\"github\")\n",
    "\n",
    "graph = reader.get_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzjKIR8rWar3"
   },
   "source": [
    "#### Node Sampling\n",
    "\n",
    "We will first look at some popular node sampling algorithms. Let\u2019s use the PageRank Proportional Node Sampling method from [Sampling From Large Graphs](https://cs.stanford.edu/people/jure/pubs/sampling-kdd06.pdf). We will sample approximately 50% of the original nodes from the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz2ydn6yWar3"
   },
   "outputs": [],
   "source": [
    "from littleballoffur import PageRankBasedSampler, RandomNodeSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GNma5AgsWar3"
   },
   "outputs": [],
   "source": [
    "number_of_nodes = int(0.5*graph.number_of_nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MKY3KQ3War3"
   },
   "outputs": [],
   "source": [
    "pagerank_sampler = PageRankBasedSampler(number_of_nodes = number_of_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_254ZTF2War3"
   },
   "outputs": [],
   "source": [
    "randomnode_sampler = RandomNodeSampler(number_of_nodes = number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-GYVh9fNWar3"
   },
   "outputs": [],
   "source": [
    "randomnodes_graph = pagerank_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h17w9rV5War3"
   },
   "outputs": [],
   "source": [
    "pagerank_graph = pagerank_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_XNYCN4War3"
   },
   "source": [
    "#### Sub-graph Sampling\n",
    "\n",
    "We also look at a series of sampling algorithms that sample sub-graphs from larger graphs.\n",
    "\n",
    "First is an implementation of node sampling by random walks--a simple random walker that creates an induced subgraph by wandering around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9QPA9ZLWar3"
   },
   "outputs": [],
   "source": [
    "from littleballoffur import RandomWalkSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxwRWXdCWar3"
   },
   "outputs": [],
   "source": [
    "randomwalk_sampler = RandomWalkSampler(number_of_nodes=number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fx7T5HEHWar3"
   },
   "outputs": [],
   "source": [
    "randomwalk_graph = randomnode_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fm6pi-BWar4"
   },
   "source": [
    "Now let\u2019s use the Metropolis-Hastings Random Walk Sampler method from [Metropolis Algorithms for Representative Subgraph Sampling](https://ieeexplore.ieee.org/document/4781123).  The random walker has a probabilistic acceptance condition for adding new nodes to the sampled node set. This constraint can be parametrized by the rejection constraint exponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Kw-L1rOWar4"
   },
   "outputs": [],
   "source": [
    "from littleballoffur import MetropolisHastingsRandomWalkSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "udAvoDT_War4"
   },
   "outputs": [],
   "source": [
    "mhrw_sampler = MetropolisHastingsRandomWalkSampler(number_of_nodes = number_of_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8bi_YFVWar4"
   },
   "outputs": [],
   "source": [
    "mhrw_graph = mhrw_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELN_Y7W9War4"
   },
   "source": [
    "You will find many other sub-graph sampling algorithms, and many variations of the Random Walk algorithm (RandomWalkWithJumpSampler, RandomNodeNeighborSampler, RandomWalkWithRestartSampler) in the [Exploration Sampling](https://little-ball-of-fur.readthedocs.io/en/latest/modules/exploration_sampling.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUMQhZ58War4"
   },
   "source": [
    "\n",
    "## Non-probabilistic Sampling and Extensions\n",
    "\n",
    "A lot of the sampling we will see in this section involves sampling over a network or graph. For example, in a survey, we may ask one respondent to choose the next, and in that way create a sub-graph within the full social graph from which we seek to sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsqKZzCgWar4"
   },
   "source": [
    "### Snowball Sampling\n",
    "\n",
    "Snowball sampling is where research participants recruit others for a test or study. It is used where potential participants are hard to find. It\u2019s called snowball sampling because (in theory) once you have the ball rolling, it picks up more \u201csnow\u201d along the way and becomes larger and larger. Snowball sampling is a non-probability sampling method. ([link to explanation](https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/snowball-sampling/))\n",
    "\n",
    "If we manually inspect the sampling, we can add our own criteria for stopping; in the package implementation, it stops when we have enough samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_9Ctn8lWar4"
   },
   "outputs": [],
   "source": [
    "from littleballoffur import SnowBallSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iU1S0M8War4"
   },
   "outputs": [],
   "source": [
    "snowball_sampler = SnowBallSampler(number_of_nodes = number_of_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TLrvk_rWar4"
   },
   "outputs": [],
   "source": [
    "snowball_graph = snowball_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb9REB84War4"
   },
   "source": [
    "littleballoffur also offers stochastic extensions of the Snowball Sampler. The Forest Fire Sampler is a stochastic snowball sampling method where the expansion is proportional to the burning probability, described [here](https://cs.stanford.edu/people/jure/pubs/sampling-kdd06.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2G0wGYfWar4"
   },
   "outputs": [],
   "source": [
    "from littleballoffur import ForestFireSampler, SpikyBallSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMUwXQLZWar4"
   },
   "outputs": [],
   "source": [
    "forestfire_sampler = ForestFireSampler(number_of_nodes=number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zpda8-5_War4"
   },
   "outputs": [],
   "source": [
    "forestfire_graph = forestfire_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIsB-OC6War4"
   },
   "source": [
    "Below we use spiky ball sampling. The procedure is a filtered breadth-first search sampling method where the expansion is performed over a random subset of neighbors. Originally described [here](https://www.mdpi.com/1999-4893/13/11/275)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TRxzcLlWar4"
   },
   "outputs": [],
   "source": [
    "spikyball_sampler = SpikyBallSampler(number_of_nodes=number_of_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-butVu3uWar4"
   },
   "outputs": [],
   "source": [
    "spikyball_graph = spikyball_sampler.sample(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_jojsY_War4"
   },
   "source": [
    "We note that [Respondent-driven sampling](http://www.respondentdrivensampling.org/) and the [Network Scale-up method](https://journals.sagepub.com/doi/full/10.1177/0081175016665425) extend the snowball to improve inference.\n",
    "\n",
    "That's the last of our graph based sampling. We will now discuss some other methods used. Note that the following sections are theoretical with no code, but the previous code can help you implement these methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6ZB-YCrWar4"
   },
   "source": [
    "### Convenience\n",
    "\n",
    "This simply refers to using a sample that is at-hand and easy to analyse. For example, you may choose a free sub-graph of the full Facebook friend graph to run experiments because you do not have access to more data. You can refine your methods on this data before moving on to a larger dataset.\n",
    "\n",
    "You can read more about it [here](https://methods.sagepub.com/reference/encyclopedia-of-survey-research-methods/n105.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7DWHT8uWar4"
   },
   "outputs": [],
   "source": [
    "# empty cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzaMuE5PWar4"
   },
   "source": [
    "### Quota Sampling\n",
    "\n",
    "Very similar to stratified sampling, but we may not randonly sample from the strata and choose the whole sample according to these desired traits or qualities. Here are some links to read more:\n",
    "\n",
    "- [QuestionPro: Quota Sampling definition](https://www.questionpro.com/blog/quota-sampling/#:~:text=Quota%20sampling%20is%20defined%20as,to%20specific%20traits%20or%20qualities.)\n",
    "- [Statistics How To: Quota Sampling](https://www.statisticshowto.com/quota-sampling/)\n",
    "- [humansofdata: Quota Sampling](https://humansofdata.atlan.com/2016/04/quota-sampling-when-to-use-how-to-do-correctly/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wduVVJpUWar5"
   },
   "outputs": [],
   "source": [
    "# empty cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXfUUKasWar5"
   },
   "source": [
    "### Purposive / Relevance / Judgement sampling\n",
    "\n",
    "[A useful blog post](https://www.alchemer.com/resources/blog/purposive-sampling-101/)\n",
    "\n",
    "[Paper: Purposeful sampling for qualitative data collection and analysis in mixed method implementation research](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4012002/)\n",
    "\n",
    "Purposive sampling, also known as judgmental, selective, or subjective sampling, is a form of non-probability sampling in which researchers rely on their own judgment when choosing members of the population to participate in their surveys.\n",
    "\n",
    "This survey sampling method requires researchers to have prior knowledge about the purpose of their studies so that they can properly choose and approach eligible participants for surveys conducted.\n",
    "\n",
    "Researchers use purposive sampling when they want to access a particular subset of people, as all participants of a survey are selected because they fit a particular profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9C-Xhy2zWar5"
   },
   "outputs": [],
   "source": [
    "# empty cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7UCVits2War5"
   },
   "source": [
    "## Sampling Imbalanced Classes\n",
    "\n",
    "A common problem we deal with in real world datasets is imbalance, when we have one (or a few) class, category or sections that have higher or lower representation than the other classes. This situation is often referred to as having imbalanced classes, and the python package [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) is specifically built to tackle this, although one can frame this as a stratified sampling problem, as described above.\n",
    "\n",
    "In this section we will be drawing on a tutorial by [Investigate.ai](https://investigate.ai/), a school for teaching data science to journalists. The tutorial we will follow is in this [repository](https://github.com/littlecolumns/ds4j-notebooks/blob/master/classification/notebooks/Correcting%20for%20imbalanced%20datasets.ipynb).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkwY77uMWar5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KprOYMGLWar5"
   },
   "source": [
    "### Classification problems with imbalanced inputs\n",
    "\n",
    "Oftentimes when we're doing real-world classification, we have the problem of **\"imbalanced classes\"**.\n",
    "\n",
    "Let's say we're analyzing a document dump, and trying to find documents interesting to us. Maybe we're only interested in 10% of them! The fact that there's such a bias - 90% are uninteresting - **can damage the accuracy of our classifier.** Let's take a look at [imbalanced-learn](https://imbalanced-learn.readthedocs.io/en/stable/) library to help address this challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIIZAHo1War5"
   },
   "source": [
    "### Prep work: Downloading necessary files\n",
    "First, we need to download the following data.\n",
    "* **recipes-indian.csv:** Indian classification recipes - a selection of recipe ingredient lists, half of them being labeled as Indian cuisine.\n",
    "* **recipes.csv:** recipes - a selection of recipe ingredient lists, each labeled with the cuisine from which it hearkens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umShrekcWar5",
    "outputId": "f87bad3f-a98a-409a-fdb6-fc8ada0ed868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-17 04:34:12--  https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/classification/data/recipes-indian.csv\n",
      "Resolving nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)... 162.243.189.2\n",
      "Connecting to nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)|162.243.189.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1033379 (1009K) [text/csv]\n",
      "Saving to: \u2018data/recipes-indian.csv\u2019\n",
      "\n",
      "\rrecipes-indian.csv    0%[                    ]       0  --.-KB/s               \rrecipes-indian.csv  100%[===================>]   1009K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2022-04-17 04:34:12 (23.7 MB/s) - \u2018data/recipes-indian.csv\u2019 saved [1033379/1033379]\n",
      "\n",
      "--2022-04-17 04:34:12--  https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/classification/data/recipes.csv\n",
      "Resolving nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)... 162.243.189.2\n",
      "Connecting to nyc3.digitaloceanspaces.com (nyc3.digitaloceanspaces.com)|162.243.189.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6483086 (6.2M) [text/csv]\n",
      "Saving to: \u2018data/recipes.csv\u2019\n",
      "\n",
      "recipes.csv         100%[===================>]   6.18M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-04-17 04:34:12 (59.7 MB/s) - \u2018data/recipes.csv\u2019 saved [6483086/6483086]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make data directory if it doesn't exist\n",
    "!mkdir -p data\n",
    "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/classification/data/recipes-indian.csv -P data\n",
    "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/classification/data/recipes.csv -P data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpNE3EBEWar5"
   },
   "source": [
    "You should be familiar with vectorizing, classification, and confusion matrices going in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGzbDT0yWar5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icuhF73LWar5"
   },
   "source": [
    "### Our datasets\n",
    "\n",
    "We're going to be looking at two datasets: They're both **recipes and ingredient lists**, and with both we're predicting whether we can **accurately determine which recipes are Indian**.\n",
    "\n",
    "Let's read both in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uAfEbzbWar5",
    "outputId": "d3e7a0ff-4c9c-4898-a910-4950aca4bede"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-45163f5c-4dc2-4802-a5b5-2ebb9a7f5833\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredient_list</th>\n",
       "      <th>is_indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>indian</td>\n",
       "      <td>23348</td>\n",
       "      <td>minced ginger, garlic, oil, coriander powder, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indian</td>\n",
       "      <td>18869</td>\n",
       "      <td>chicken, chicken breasts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indian</td>\n",
       "      <td>36405</td>\n",
       "      <td>flour, rose essence, frying oil, powdered milk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>11494</td>\n",
       "      <td>soda, ghee, sugar, khoa, maida flour, milk, oil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>32675</td>\n",
       "      <td>tumeric, garam masala, salt, chicken, curry le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45163f5c-4dc2-4802-a5b5-2ebb9a7f5833')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-45163f5c-4dc2-4802-a5b5-2ebb9a7f5833 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-45163f5c-4dc2-4802-a5b5-2ebb9a7f5833');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  cuisine     id                                    ingredient_list  is_indian\n",
       "0  indian  23348  minced ginger, garlic, oil, coriander powder, ...          1\n",
       "1  indian  18869                           chicken, chicken breasts          1\n",
       "2  indian  36405  flour, rose essence, frying oil, powdered milk...          1\n",
       "3  indian  11494    soda, ghee, sugar, khoa, maida flour, milk, oil          1\n",
       "4  indian  32675  tumeric, garam masala, salt, chicken, curry le...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_balanced = pd.read_csv(\"data/recipes-indian.csv\")\n",
    "df_balanced['is_indian'] = (df_balanced.cuisine == \"indian\").astype(int)\n",
    "\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scNGVoMQWar5",
    "outputId": "652317e1-bf70-4776-f567-c5ab2f78c616"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c52398ae-b5df-42dc-8af8-3f792517ac44\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredient_list</th>\n",
       "      <th>is_indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>romaine lettuce, black olives, grape tomatoes,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>plain flour, ground pepper, salt, tomatoes, gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>eggs, pepper, salt, mayonaise, cooking oil, gr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>water, vegetable oil, wheat, salt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>black pepper, shallots, cornflour, cayenne pep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c52398ae-b5df-42dc-8af8-3f792517ac44')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c52398ae-b5df-42dc-8af8-3f792517ac44 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c52398ae-b5df-42dc-8af8-3f792517ac44');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       cuisine     id                                    ingredient_list  \\\n",
       "0        greek  10259  romaine lettuce, black olives, grape tomatoes,...   \n",
       "1  southern_us  25693  plain flour, ground pepper, salt, tomatoes, gr...   \n",
       "2     filipino  20130  eggs, pepper, salt, mayonaise, cooking oil, gr...   \n",
       "3       indian  22213                  water, vegetable oil, wheat, salt   \n",
       "4       indian  13162  black pepper, shallots, cornflour, cayenne pep...   \n",
       "\n",
       "   is_indian  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_unbalanced = pd.read_csv(\"data/recipes.csv\")\n",
    "df_unbalanced['is_indian'] = (df_unbalanced.cuisine == \"indian\").astype(int)\n",
    "\n",
    "df_unbalanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CE_nIoabWar5"
   },
   "source": [
    "They both look similar enough, right? A list of ingredients and an `is_indian` target column we'll use as our label.\n",
    "\n",
    "### Finding the imbalance\n",
    "\n",
    "The real difference is how many recipes are Indian in each dataset. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGWtFmzsWar5",
    "outputId": "35e9bafa-eea4-40f8-bd5e-c68edab87266"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3000\n",
       "0    3000\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_balanced.is_indian.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMTCje1AWar5",
    "outputId": "2bfa9c7b-b6d1-4237-8d60-222097f6646e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36771\n",
       "1     3003\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_unbalanced.is_indian.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEgkrscCWar5"
   },
   "source": [
    "Ouch! That second dataset is extremely uneven - over ten times as many non-Indian recipes as Indian ones!\n",
    "\n",
    "The problem is: **this is usually how data looks in the real world.** You rarely have even numbers between your classes if you did not collect the data with this classification in mind, and you often think \"more data is better data.\" We'll see how it plays out when we actually run our classifiers!\n",
    "\n",
    "### Testing our datasets\n",
    "\n",
    "We're going to use a `TfidfVectorizer` to convert ingredient lists to numbers, run a test/train split, and then train (and test) a `LinearSVC` classifier on the results. We'll start with the **balanced dataset**.\n",
    "\n",
    "### Balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR9QcDwZWar5",
    "outputId": "12f4b20f-c49f-4f38-ab70-5a82756d994b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3000\n",
       "0    3000\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a vectorizer and train it\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(df_balanced.ingredient_list)\n",
    "\n",
    "# Features are our matrix of tf-idf values\n",
    "# labels are whether each recipe is Indian or not\n",
    "X = matrix\n",
    "y = df_balanced.is_indian\n",
    "\n",
    "# How many are Indian?\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5fZC1fLWar5"
   },
   "source": [
    "We still have an even split, 3000 non-Indian recipes and 3000 Indian recipes. Let's run a test/train split and see how the results look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDWGdosqWar5",
    "outputId": "90fa1519-e1ce-4671-f2c5-273e976a239a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7ff1c4bc-d180-4b4a-b465-11651acdc702\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted not indian</th>\n",
       "      <th>Predicted indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is not indian</th>\n",
       "      <td>0.966988</td>\n",
       "      <td>0.033012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is indian</th>\n",
       "      <td>0.059508</td>\n",
       "      <td>0.940492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ff1c4bc-d180-4b4a-b465-11651acdc702')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7ff1c4bc-d180-4b4a-b465-11651acdc702 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7ff1c4bc-d180-4b4a-b465-11651acdc702');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               Predicted not indian  Predicted indian\n",
       "Is not indian              0.966988          0.033012\n",
       "Is indian                  0.059508          0.940492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Build a classifier and train it\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test our classifier and build a confusion matrix\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not indian', 'indian'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKKR7oIPWar6"
   },
   "source": [
    "**Our classifier looks pretty good!** Around 96% accuracy for predicting non-Indian food, and around 95% correctly predicting Indian food. High quality *and* even.\n",
    "\n",
    "Let's move on to see how it looks with our **unabalanced dataset**.\n",
    "\n",
    "### Unbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2Obq8r3War6",
    "outputId": "32daf17c-0d37-4dcc-9d10-d7eb0bfe182c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36771\n",
       "1     3003\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a vectorizer and train it\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(df_unbalanced.ingredient_list)\n",
    "\n",
    "# Features are our matrix of tf-idf values\n",
    "# labels are whether each recipe is Indian or not\n",
    "X = matrix\n",
    "y = df_unbalanced.is_indian\n",
    "\n",
    "# How many are Indian?\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ePD8-PZWar6"
   },
   "source": [
    "Again: around 36k non-Indian recipes massively outweighing the 3,003 Indian recipes. While we love the world of big data, let's see what that imbalance does to our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQOzc_MoWar6",
    "outputId": "f2728a72-9c3a-418f-a268-63359427575e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9792a264-ded9-4df9-b0c6-753cbd6fffed\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted not indian</th>\n",
       "      <th>Predicted indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is not indian</th>\n",
       "      <td>0.992817</td>\n",
       "      <td>0.007183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is indian</th>\n",
       "      <td>0.168212</td>\n",
       "      <td>0.831788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9792a264-ded9-4df9-b0c6-753cbd6fffed')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9792a264-ded9-4df9-b0c6-753cbd6fffed button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9792a264-ded9-4df9-b0c6-753cbd6fffed');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               Predicted not indian  Predicted indian\n",
       "Is not indian              0.992817          0.007183\n",
       "Is indian                  0.168212          0.831788"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split our dataset is train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test our classifier and build a confusion matrix\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not indian', 'indian'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjz2t0rzWar6"
   },
   "source": [
    "Ouch!!! While we're doing **really well** at predicting non-Indian dishes, our ability to predict Indian dishes has plummeted to just over 80%.\n",
    "\n",
    "Why? An easy way to think about it is **when it's a risky or rare decision, it's always safest to guess \"not Indian.\"** In fact, if we *always guessed non-Indian*, no matter what, we'd be right..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCc_G4q_War6",
    "outputId": "392269a1-de21-4a18-cf1d-4283572a1af8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9244984160506864"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "36771/(36771+3003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cATwmLFYWar6"
   },
   "source": [
    "About 92% of the time! So how do we solve this problem?\n",
    "\n",
    "### Solving the problem\n",
    "\n",
    "Solving the problem of unbalanced (or biased) input classes is not too hard! There's a nice library that can give us a hand, [imbalanced-learn](https://imbalanced-learn.readthedocs.io/en/stable/).\n",
    "\n",
    "imbalanced-learn will **resample** our dataset, either generating new datapoints or pruning out existing datapoints, until the classes are evened--providing a class-stratified sample.\n",
    "\n",
    "#### What do we resample?\n",
    "\n",
    "An important thing to note is that **bias occurs when we train our model.** If we show our model a skewed view of the world, it'll carry that bias when making judgments in the future. When we add or remove datapoints to even the problem, **we only need to do this for the training data.**\n",
    "\n",
    "We want to show the model an even view of the world, so we give it even data. The test data should still reflect the \"real\" world. Before we were looking at how imbalanced our overall dataset was, but now let's **just look at how biased the training data is.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKAmpVEuWar6",
    "outputId": "ace60003-c187-4106-a2f6-f6f87f5c79cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27582\n",
       "1     2248\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOpKJqPYWar6",
    "outputId": "6911c988-847e-456d-ff63-2a377d00d72b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.92464\n",
       "1    0.07536\n",
       "Name: is_indian, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju07fBE7War6"
   },
   "source": [
    "Looks like a little over 7% of our training data is Indian - we'd like to get that up to 50%, so let's see what the imbalanced-learn library can do for us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McZ3fNVhWar6"
   },
   "source": [
    "#### Undersampling\n",
    "\n",
    "If we're feeling guilty that there are so many additional non-Indian recipes, *we could always get rid of those extra non-Indian recipes!* In fact, the balanced dataset manually created to form an even split of Indian/non-Indian recipes.\n",
    "\n",
    "Instead of manually digging through our dataset to even things out, though, we can rely on imbalanced-learn to do it automatically. We'll use the technique of **undersampling** to take those ~28k non-Indian recipes and randomly filter them down to around 2,000 to match the number of Indian recipes. (Remember we're only doing this with training data!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cI94efqIWar6",
    "outputId": "81b69525-7c76-4501-fd12-51dc1463fa00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2248\n",
       "1    2248\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "resampler = RandomUnderSampler()\n",
    "# Resample X and y so there are equal numbers of each y\n",
    "X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)\n",
    "\n",
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymYNDMQHWar6"
   },
   "source": [
    "Awesome; equal numbers! Let's see how the classifier performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Pbqgb9UWar6",
    "outputId": "e30d30d5-ff86-4e5d-b385-32e27f87d2eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e565b922-366e-4089-a2be-ece4ba38e14c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted not indian</th>\n",
       "      <th>Predicted indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is not indian</th>\n",
       "      <td>0.96017</td>\n",
       "      <td>0.03983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is indian</th>\n",
       "      <td>0.04106</td>\n",
       "      <td>0.95894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e565b922-366e-4089-a2be-ece4ba38e14c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e565b922-366e-4089-a2be-ece4ba38e14c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e565b922-366e-4089-a2be-ece4ba38e14c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               Predicted not indian  Predicted indian\n",
       "Is not indian               0.96017           0.03983\n",
       "Is indian                   0.04106           0.95894"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We already split our data, so we don't need to do that again\n",
    "\n",
    "# Train the classifier on the resampled training data\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Build a confusion matrix\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not indian', 'indian'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRmelvuQWar6"
   },
   "source": [
    "Looking good! It performs as well as our other 3,000/3,000 split because, well, it's more or less the same thing (although the test data is \"realistically\" unbalanced)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbXACFclWar6"
   },
   "source": [
    "#### Oversampling\n",
    "\n",
    "Cutting out those 27,000 \"extra\" non-Indian recipes seems like such a bummer, though. Wouldn't it be nice if we somehow found another 25,000 Indian recipes to even up our unbalanced training dataset to 27k non-Indian and 27k Indian? It's possible with **oversampling!**\n",
    "\n",
    "Oversampling generates **new datapoints** based on your existing dataset. In this case we're going to use the `RandomOverSampler`, which just fills our dataset with **copies of the less-included class**. This is a form of data augmentation, described earlier when we generated additional image data through copying, perturbing and noising data. In this case, we'll have 27k Indian recipes, *but they'll be 25,0000 copies of the original ones*. Can that possibly help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mM9t5yvvWar6"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "resampler = RandomOverSampler()\n",
    "X_train_resampled, y_train_resampled = resampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HZx9BbQWar6",
    "outputId": "904bae94-3b21-4d36-a966-9b79f4ef87ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27582\n",
       "1    27582\n",
       "Name: is_indian, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN7J_72MWar6"
   },
   "source": [
    "Looking good, a nice even 27,599 apiece. Let's see how the classifier works out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_2X8ZIeWar6",
    "outputId": "20bc551a-0f7b-4cc4-d385-453eabb567cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7bf5d12d-b1b4-4fbd-94b8-9361ba86962e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted not indian</th>\n",
       "      <th>Predicted indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Is not indian</th>\n",
       "      <td>0.973120</td>\n",
       "      <td>0.026880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is indian</th>\n",
       "      <td>0.064901</td>\n",
       "      <td>0.935099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bf5d12d-b1b4-4fbd-94b8-9361ba86962e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7bf5d12d-b1b4-4fbd-94b8-9361ba86962e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7bf5d12d-b1b4-4fbd-94b8-9361ba86962e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               Predicted not indian  Predicted indian\n",
       "Is not indian              0.973120          0.026880\n",
       "Is indian                  0.064901          0.935099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We already split our dataset into train and test data\n",
    "\n",
    "# Train the classifier on the resampled training data\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Build a confusion matrix with the result\n",
    "y_true = y_test\n",
    "y_pred = clf.predict(X_test)\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "label_names = pd.Series(['not indian', 'indian'])\n",
    "pd.DataFrame(matrix,\n",
    "     columns='Predicted ' + label_names,\n",
    "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpj074OFWar7"
   },
   "source": [
    "Also looking pretty good! A little bit better at predicting non-Indian dishes and a little bit worse at predicting Indian dishes, but very simimlar to the undersampled example.\n",
    "\n",
    "There are also other oversampling techniques that involve **creating synthetic data,** new datapoints that aren't *copies* of our data, but rather totally new ones. You can read more about them [on the imbalanced-learn page](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html) and as reflected in the homework for our notebooks on data and regularization.\n",
    "\n",
    "#### Review\n",
    "\n",
    "In this section we talked about the problem of **imbalanced classes**, where an uneven split in your labels can cause suboptimal classifier performance. We used the imbalanced-learn library to talk about two methods of solving the issue - undersampling and oversampling - which both boosted performance as compared to the imbalanced dataset by stratifying data on the class of interest.\n",
    "\n",
    "#### Discussion topics\n",
    "\n",
    "What is the difference between oversampling and undersampling? Why might have oversampling done a better job predicting non-Indian recipes?\n",
    "\n",
    "Why did we only resample the training data, and not the test data?\n",
    "\n",
    "While the idea of automatically-generated fake data might sound more attractive than just re-using existing data, [what might be some issues with it](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html)?\n",
    "\n",
    "Can we think of any times when we might *not* want a balanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4FJXaWgWar7"
   },
   "source": [
    "You can find more examples with imbalanced datasets in the [example gallery](https://imbalanced-learn.org/stable/auto_examples/index.html#general-examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ArFWCTy-War7"
   },
   "source": [
    "## Bootstrap sampling and sub-sampling\n",
    "\n",
    "Bootstrap sampling and sub-sampling are two methods that are particularly relevant in the context of machine and deep learning for drawing inferences from our models.\n",
    "\n",
    "[text drawn from this blog](https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/).\n",
    "\n",
    "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset **with replacement**. A bootstrap sample of a population excludes some data points (at random), and duplicates others.\n",
    "\n",
    "Because bootstrap samples have the potential to exclude outliers, they can be used to estimate summary statistics such as the mean, standard deviation, or a confidence interval (e.g., 95%). It is used in applied machine learning to estimate the performance of machine learning models when making predictions on data not included in the training data, but may also to generate confidence intervals for \"distances\", \"similarities\", \"probabilities\" or other measurements drawn from auto-encoders or similar models (like [**this**](https://journals.sagepub.com/doi/full/10.1177/0003122419877135)). Confidence intervals cannot be directly inferred from other ML methods such as cross-validation.\n",
    "\n",
    "### Bootstrap sampling example with word embeddings\n",
    "\n",
    "In this section we explore the stability of word embeddings using bootstrap sampling. This is a well researched question in NLP research ([Evaluating the Stability of Embedding-based Word Similarities](https://mimno.infosci.cornell.edu/papers/antoniak-stability.pdf)). In the paper, *the authors come to the conclusion that there are several sources of variability\n",
    "in cosine similarities between word embeddings vectors. The size of the corpus, the length of individual documents, and the presence or absence of specific documents can all affect the resulting embeddings. While differences in word association are measurable and are often significant, small differences in cosine similarity are not reliable, especially for small corpora. If the intention of a study is to learn about a specific corpus, we recommend practitioners test the statistical confidence of similarities based on word embeddings by training on multiple bootstrap samples.*\n",
    "\n",
    "We will conduct a mini-version of this experiment to test how stable word similarities are after training with and without bootrstrap sampling on a smaller text dataset. We use a dataset we used before, the hobbies dataset. We note that bootstrapping can be performed with a deep auto-encoder or any deep model from which we seek to assess generalizable inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGX-Ar29War7"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50aOprBnWar7"
   },
   "outputs": [],
   "source": [
    "from yellowbrick.datasets import load_hobbies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leCL-ErWWar7"
   },
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yu1Zq5k4War7"
   },
   "outputs": [],
   "source": [
    "corpus = load_hobbies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfuYFf2uWar7"
   },
   "outputs": [],
   "source": [
    "preprocessed_texts = preprocess_documents(corpus.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ttn6xAUcWar7",
    "outputId": "f83ab02e-9d72-4210-c1b3-6f6c875144e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(preprocessed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJytV-WkWar7"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYfJEoE6War7"
   },
   "outputs": [],
   "source": [
    "w2vmodel_cleaned = Word2Vec(\n",
    "        preprocessed_texts,\n",
    "        vector_size=100,\n",
    "        window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qSn7Ca8War7",
    "outputId": "342645c8-4c56-47b5-fb1c-1b66f9220950"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stori', 0.9999245405197144),\n",
       " ('approach', 0.9999086856842041),\n",
       " ('movi', 0.9999039173126221),\n",
       " ('show', 0.9999037981033325),\n",
       " ('reveal', 0.9999029636383057),\n",
       " ('live', 0.9999018311500549),\n",
       " ('left', 0.9999016523361206),\n",
       " ('illustr', 0.9999004602432251),\n",
       " ('todai', 0.9999003410339355),\n",
       " ('group', 0.9998995065689087)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2vmodel_cleaned.wv.most_similar(\"book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBDwh8M2War7"
   },
   "source": [
    "We use this as a reference while we explore how stable the model is with two sets of bootstrapped texts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SVmvVtyFWar7"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aqscb2BJWar7"
   },
   "outputs": [],
   "source": [
    "bootstrap_texts = resample(preprocessed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uk6n8d1sWar7",
    "outputId": "f7f49c7f-53f1-46b1-b026-4e38482e49fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(bootstrap_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MpfjbbyWWar7"
   },
   "outputs": [],
   "source": [
    "w2vmodel_boot = Word2Vec(\n",
    "        bootstrap_texts,\n",
    "        vector_size=100,\n",
    "        window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a455Fj08War7",
    "outputId": "2441ae73-4114-47b8-a47f-6fdb9b64f87b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stori', 0.9996894001960754),\n",
       " ('author', 0.999585747718811),\n",
       " ('war', 0.9995577335357666),\n",
       " ('film', 0.9995225667953491),\n",
       " ('movi', 0.9995080828666687),\n",
       " ('publish', 0.9994944334030151),\n",
       " ('writer', 0.9994939565658569),\n",
       " ('novel', 0.9994746446609497),\n",
       " ('charact', 0.9994713664054871),\n",
       " ('compani', 0.9994663000106812)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2vmodel_boot.wv.most_similar(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8cA-s2wWar7"
   },
   "outputs": [],
   "source": [
    "bootstrap_texts_1 = resample(preprocessed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkbmcYGdWar7"
   },
   "outputs": [],
   "source": [
    "w2vmodel_boot_1 = Word2Vec(\n",
    "        bootstrap_texts_1,\n",
    "        vector_size=100,\n",
    "        window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5BXdumvbWar7",
    "outputId": "c05c11b9-06cc-4a4a-e22c-9a91f5f1ed76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stori', 0.9998213648796082),\n",
       " ('novel', 0.9998008012771606),\n",
       " ('comic', 0.9997929930686951),\n",
       " ('author', 0.9997838735580444),\n",
       " ('write', 0.999782383441925),\n",
       " ('there\u2019', 0.9997755289077759),\n",
       " ('writer', 0.999765932559967),\n",
       " ('audienc', 0.9997559785842896),\n",
       " ('movi', 0.9997525811195374),\n",
       " ('broken', 0.9997516870498657)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w2vmodel_boot_1.wv.most_similar(\"book\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HivZfv2lWar7"
   },
   "source": [
    "Smaller corpora are likely to be more variable in their embeddings; when bootstrapped we see this more clearly. We encourage you to read the paper on stability in word embeddings and to run your own experiments with your datasets.\n",
    "\n",
    "### Confidence intervals\n",
    "\n",
    "How do we add a confidence interval to one of these cosine distances (e.g., the cosine similarity between \"book\" and \"stori\") with bootstrap sampling?\n",
    "\n",
    "For example, if we assume the texts underlying our word embedding model are observations drawn from an independent and identically distributed (i.i.d.) population of cultural observations, then bootstrapping allows us to estimate the variance of word distances and projections by measuring those properties through sampling the empirical distribution of texts with replacement (Efron 2003; Efron and Tibshirani 1994).\n",
    "\n",
    "To estimate bootstrapped 90 percent confidence intervals, the analyst draws documents with replacement from the corpus to construct 20 new corpora, each the size of the original corpus. The analyst then estimates either word similarities or angles between vectors on all 20 of these new corpora. The 2nd order (2nd smallest) estimated statistic $s(2)$ is taken as the confidence interval\u2019s lower bound and the 19th order statistic $s(19)$ as its upper bound. The distance between $s(2)$ and $s(19)$ across 20 bootstrap samples span the 5th to the 95th percentiles of the statistic\u2019s variance, bounding the 90th confidence interval. A 95 percent confidence interval would span $s(2)$ and $s(39)$ in word embedding distances or projections estimated on 40 bootstrap samples of a corpus, tracing the 2.5th to 97.5th percentiles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHvwyQSaWar8"
   },
   "outputs": [],
   "source": [
    "word_differences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HwqhC6-EWar8",
    "outputId": "63f999a7-c76d-484c-f9ab-d194b60ffc68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "  bootstrap_texts = resample(preprocessed_texts)\n",
    "  w2vmodel_boot = Word2Vec(\n",
    "        bootstrap_texts,\n",
    "        vector_size=100,\n",
    "        window=10)\n",
    "  word_differences.append(w2vmodel_boot.similarity('book', 'stori'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUOGI1E2War8"
   },
   "outputs": [],
   "source": [
    "sorted_diffs = sorted(word_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySJQpkrtWar8",
    "outputId": "68daeda8-25cf-413a-92fd-d50fd8b78b7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9910327,\n",
       " 0.9961562,\n",
       " 0.99721795,\n",
       " 0.99822146,\n",
       " 0.99870205,\n",
       " 0.9987051,\n",
       " 0.9991782,\n",
       " 0.9992429,\n",
       " 0.99959224,\n",
       " 0.99960154,\n",
       " 0.99964875,\n",
       " 0.99966174,\n",
       " 0.9996634,\n",
       " 0.9997253,\n",
       " 0.99974334,\n",
       " 0.99976045,\n",
       " 0.9998034,\n",
       " 0.99982756,\n",
       " 0.99983954,\n",
       " 0.9999032]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qNVD0GxWar8",
    "outputId": "8c82b37c-9557-4d0e-d762-6c4bf1e0f870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036833286"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_diffs[18] - sorted_diffs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JWpkoqwlWar8",
    "outputId": "3acae289-bb20-4f73-fd60-a4bc7cb78c9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9961562, 0.99983954)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(sorted_diffs[1], sorted_diffs[18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hisB6SleWar8"
   },
   "source": [
    "We have a 90% confidence interval that the difference between book and stori lies between (0.99588996, 0.999865)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIX-ZJvHWar8"
   },
   "source": [
    "### Sub-sampling\n",
    "\n",
    "Unlike bootstrap sampling, in sub-sampling we sample without replacement, usually in cases when we are dealing with very large data and only want a portion of it. [subsample](https://pypi.org/project/subsample/) is a python package that works as a command-line tool for sub-sampling, and is especially powerful with text based datasets. It includes methods such as reservoir sampling and two pass sampling.\n",
    "\n",
    "Subsampling also refers to the process of randomly partitioning your dataset and running the same algorithm (e.g., your deep model) on each subsample, then using these to estimate statistics like the mean, standard deviation or confidence intervals. It is especially useful when the data is large, model optimization is slow, and running the same model on smaller data yields superlinear speed increases (as with [**this case**](https://journals.sagepub.com/doi/full/10.1177/0003122419877135)) of text auto-encoders.)\n",
    "\n",
    "By randomly partitioning the data (e.g., a corpus of texts) into non-overlapping samples, estimates of neural network models on these subsets allow calculation of confidence or credible intervals as a function of the empirical distribution of distance or projection statistics and number of texts in the subsample (Politis, Romano, and Wolf 1997). Subsampling relies on the same i.i.d. assumption as the bootstrap (Politis and Romano 1992, 1994). For 90 percent confidence intervals, we randomly partition the corpus into 20 subcorpora, then calculate the error of our embedding distance or projection statistic s for each subsample $k$ as $B^k=\\sqrt{\\tau^k}(s^k\u2212\\bar{s})$, where $\\tau^k$ is the number of texts in subsample $k$, $s^k$ is the embedding distance or projection for the $k$th sample, and $\\bar{s}$ is the mean of the 20 estimates. The 90 percent confidence interval spans the 5th to 95th percentile variances, inscribed by $\\bar{s}-\\frac{B^k(19)}{\\sqrt{\\tau}}$ and $\\bar{s}-\\frac{B^k(2)}{\\sqrt{\\tau^k}}$ where $\\tau$ is the number of texts in the total corpus. As with bootstrapping, a 95 percent confidence interval would require 40 subsamples; a 99 percent confidence would require 200 (.5th to 99.5th percentiles).\n",
    "\n",
    "NOTE: since this dataset is really small, it doesn't really make sense to do sub-sampling; but for the sake of demonstrating it we will have code below for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvZL9WH2War8"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AEQFCgwKWar8"
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(preprocessed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkRTWu3aWar8",
    "outputId": "64f5fb83-4a6d-43e7-fc7d-1ad83d26c02b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.47826086956522"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(preprocessed_texts) / 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiV8zIZCWar8"
   },
   "outputs": [],
   "source": [
    "chunks = [preprocessed_texts[x:x+23] for x in range(0, len(preprocessed_texts), 23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgNWR_JxWar8",
    "outputId": "caecc980-0781-4049-bde5-57308be2a3ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kevork',\n",
       " 'djansezian',\n",
       " 'getti',\n",
       " 'imag',\n",
       " 'kobe',\n",
       " 'bryant',\n",
       " 'hadn',\n",
       " 'top',\n",
       " 'point',\n",
       " 'game']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunks[0][0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36CSFHsFWar8",
    "outputId": "922b3e56-43b5-412d-cba3-9a34899dcc0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DiBVfaKAWar8"
   },
   "outputs": [],
   "source": [
    "word_differences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZNSldZfWar8",
    "outputId": "97f81db8-9a1a-49d1-8dd6-482d123e6112"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended random value\n",
      "Appended random value\n",
      "Appended random value\n",
      "Appended random value\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 20):\n",
    "  sub_sampled = chunks[i]\n",
    "  w2vmodel_sub = Word2Vec(\n",
    "        sub_sampled,\n",
    "        vector_size=100,\n",
    "        window=10)\n",
    "  try:\n",
    "    word_differences.append(w2vmodel_sub.similarity('stori', 'book'))\n",
    "  except:\n",
    "    # we wouldn't want to do this normally!!\n",
    "    # it's only because sometimes those two words don't appear in the sub-sample\n",
    "    word_differences.append(np.random.uniform((0.3, 1))[0])\n",
    "    print(\"Appended random value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H36u7ro6War8",
    "outputId": "ab7116e2-e1fb-4aed-fa00-20e01adeb826"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(word_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlX6DPSGWar8",
    "outputId": "92c7f1c5-f3af-4b7a-e361-660e9a6a4408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95981264,\n",
       " 0.96406794,\n",
       " 0.82241315,\n",
       " 0.41246882,\n",
       " 0.7836734,\n",
       " 0.7599779299501168,\n",
       " 0.28337348,\n",
       " 0.811027521593273,\n",
       " 0.9652969,\n",
       " 0.3153138,\n",
       " 0.981836,\n",
       " 0.6962260473458534,\n",
       " 0.99631363,\n",
       " 0.3317162,\n",
       " 0.7111304,\n",
       " 0.9446672,\n",
       " 0.24160936,\n",
       " 0.89898944,\n",
       " 0.38395357,\n",
       " 0.3841152534639495]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hecB-pKCWar8"
   },
   "source": [
    "**NOTE** We replace the samples where there is no book or stori with a random value between 0.3 and 1 - this is only because we have a very small dataset, with larger datasets we would expect there to be a statistic or value for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVJpx8oQWar8"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqdIWrU4War8"
   },
   "outputs": [],
   "source": [
    "mean_difference = np.mean(word_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WW5NFZwKWar8",
    "outputId": "4bd56a8b-eb98-4116-cbe8-50cfcace7528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823991362903357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NovN70YHWar9"
   },
   "outputs": [],
   "source": [
    "Bs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNkqXc58War9"
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(chunks)):\n",
    "  B = np.sqrt(len(chunks)) * (word_differences[i] - mean_difference)\n",
    "  Bs.append(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xordiodlWar9"
   },
   "outputs": [],
   "source": [
    "interval_19 = mean_difference - ((Bs[18] * word_differences[18]) / len(chunks[18]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsAwvdYtWar9"
   },
   "outputs": [],
   "source": [
    "interval_2 = mean_difference - ((Bs[1] * word_differences[1]) / len(chunks[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF5N5v6_War9",
    "outputId": "fd3e02d4-90d9-44b8-8b32-ac45475b36ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6295991823506403, 0.7046799477061303)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(interval_2, interval_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEN2vETrcWzL"
   },
   "source": [
    "## Assignment Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSWY7Y8Pcq58"
   },
   "source": [
    "**1)** Run 3 probabilistic sampling methods and 2 non-probabilistic methods and explore the samples returned. How would sampling help with your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTKcYfMPcq59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXrCCqVPcq59"
   },
   "outputs": [],
   "source": [
    "sampling_help = 'value' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HT7a8Fbcq59"
   },
   "source": [
    "**2)** Find an imbalanced dataset and build a classifier to predict the label causing the imbalance. Explore undersampling and oversampling solutions to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REPDBY-jcq59"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJlGkWN2cq5-"
   },
   "source": [
    "**3)** Use bootstrap sampling to test the stability of a word, sentence, or graph embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRrfEowxcq5-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "module2"
   },
   "source": [
    "# Module 2: Fine-Tuning with LoRA and QLoRA\n",
    "\n",
    "**Summary:** Fine-tuning neural networks involves taking a pre-trained model and adjusting its parameters allowing it to perform well on a specific task or dataset. This process sometimes involves (1) retraining all model weights, (2) unfreezing selected layers of the network and training them with a low learning rate on the new data, while keeping other layers frozen to preserve useful features learned during initial training, or (3) building adapters that translate the model weights through low-rank approaches, the purpose of this section. Fine-tuning is particularly valuable when working with limited data or computational resources, as it leverages knowledge transferred from the pre-trained model while allowing adaptation to the target task.\n",
    "\n",
    "**Readings:**\n",
    "- Hu et al. (2021) \"LoRA: Low-Rank Adaptation of Large Language Models\"\n",
    "- Dettmers et al. (2023) \"QLoRA: Efficient Finetuning of Quantized LLMs\"\n",
    "- Rafailov et al. (2023) \"Direct Preference Optimization: Your Language Model is Secretly a Reward Model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZA9G55dF6ACP"
   },
   "source": [
    "# Install & Imports\n",
    "First, we install any relevant libraries (if not already installed). This code will:\n",
    "1. Install Hugging Face Transformers (for LLM loading & training).\n",
    "2. Install bitsandbytes (if using QLoRA or 4-bit quantization).\n",
    "3. Install datasets or any other library you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zt2VOrH65aJS"
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate datasets bitsandbytes peft -q\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# For demonstration, let's just pick a small-ish model to test\n",
    "MODEL_NAME = \"facebook/galactica-125m\"  # or \"EleutherAI/gpt-neo-125M\"\n",
    "print(f\"Using model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G1BiiEp76nZz"
   },
   "source": [
    "# Background: LoRA & QLoRA\n",
    "\n",
    "# **LoRA (Low-Rank Adaptation)**:\n",
    "- Paper: _Hu et al. (2022) \u201cLoRA: Low-Rank Adaptation of Large Language Models.\u201d ICLR._\n",
    "- Key idea: Freeze the original model weights, inject trainable low-rank matrices (the \"adapters\") into attention or MLP layers. Only the adapter weights are updated. This drastically reduces parameter count for fine-tuning, so we can fit training on a single GPU or smaller hardware.\n",
    "\n",
    "# **QLoRA**:\n",
    "- Paper: _Dettmers et al. (2023) \u201cQLoRA: Efficient Finetuning of Quantized LLMs.\u201d_\n",
    "- Key idea: Quantize model weights (e.g., 4-bit) for forward/backward pass, and then add LoRA adapters. The base model remains in quantized form (saving memory), while the LoRA adapters (in higher precision) get trained.\n",
    "\n",
    "LoRA typically wraps attention projection matrices, which will detail in future weeks (LLM parameters `W_q`, `W_k`, `W_v`, or `W_out`) with low-rank decomposition. QLoRA applies 4-bit quantization on those same weight matrices, but leaves LoRA adapters in FP16 or BF16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QswXFnfk6AWo"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "# Important for causal LM tasks; we want to pad on left if doing batch inference, etc.\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# If we do standard full-precision load:\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",  # or just \"cpu\" or \"cuda:0\" depending on environment\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "\n",
    "# If we want to do a 4-bit load using bitsandbytes:\n",
    "# base_model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "#     MODEL_NAME,\n",
    "#     load_in_4bit=True,\n",
    "#     device_map=\"auto\",\n",
    "#     quantization_config=bnb.QuantizationConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_compute_dtype=torch.float16,\n",
    "#         bnb_4bit_use_double_quant=True,\n",
    "#         bnb_4bit_quant_type='nf4'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "print(\"Base model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqMjR9BaBYm-"
   },
   "source": [
    "# (Optional) Inject LoRA Adapters\n",
    "We can wrap the above model with [PEFT (Parameter-Efficient Fine-Tuning)](https://github.com/huggingface/peft) or with the original LoRA code.\n",
    "\n",
    "Below is a **PEFT**-style example (huggingface/peft) for simplicity. If you want the original LoRA or QLoRA repos, see their `train.py` scripts. The logic is mostly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5luOLp978ziQ"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"k_proj\", \"q_proj\", \"v_proj\", \"o_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model_lora = get_peft_model(base_model, lora_config)\n",
    "print(f\"LoRA Model params: {model_lora.print_trainable_parameters()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwcq-e9tBvM3"
   },
   "source": [
    "# **QLoRA**:\n",
    "If using QLoRA with bitsandbytes 4-bit quantization, we could do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuYC8z0gB6iY"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#     r=8,\n",
    "#     lora_alpha=32,\n",
    "#     target_modules=[\"query_key_value\"],\n",
    "#     lora_dropout=0.05,\n",
    "#     bias=\"none\",\n",
    "#     task_type=TaskType.CAUSAL_LM\n",
    "# )\n",
    "\n",
    "# # base_model_4bit is the quantized model\n",
    "# model_lora_4bit = get_peft_model(base_model_4bit, lora_config)\n",
    "# print(model_lora_4bit.print_trainable_parameters())\n",
    "\n",
    "# Then proceed with training, but the base weights remain 4-bit in memory, and only the LoRA adapter is stored in full precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUk6qFw-BLWU"
   },
   "source": [
    "# Prepare a Dataset\n",
    "For a small demonstration, let's create a toy text dataset or use something from Hugging Face `datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6i_P02bn9fVN"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")  # small example\n",
    "print(raw_dataset)\n",
    "\n",
    "# Let's define a data collator for causal LM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "def tokenize_function(example):\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model_lora.resize_token_embeddings(len(tokenizer))\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_dataset = raw_dataset.map(tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\"])\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,  # for causal LM\n",
    ")\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "val_dataset   = tokenized_dataset[\"validation\"]\n",
    "test_dataset  = tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DVd5yiyCMsN"
   },
   "source": [
    "# Fine-Tuning with LoRA or QLoRA\n",
    "\n",
    "We'll use the Hugging Face `Trainer` to fine-tune.\n",
    "# Training Arguments\n",
    "Key parameters to watch for:\n",
    "- `learning_rate` \u2014 might be smaller for LLM fine-tuning (e.g., 1e-4, 2e-5).\n",
    "- `per_device_train_batch_size`, `per_device_eval_batch_size`.\n",
    "- `gradient_accumulation_steps` (especially for bigger LLMs).\n",
    "- `max_steps` or `num_train_epochs`.\n",
    "- `fp16` or `bf16` if available (and stable).\n",
    "\n",
    "If QLoRA, ensure `bitsandbytes` is installed and your GPU supports 4-bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFZo0DTdCfEk"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"lora-finetune-checkpoints\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=50,\n",
    "    fp16=True,            # Enable mixed precision training if possible\n",
    "    report_to=\"none\",     # or \"wandb\", \"tensorboard\", etc.\n",
    "    max_grad_norm=1.0 # Clip gradients to prevent exploding gradients\n",
    ")\n",
    "\n",
    "# Set up the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model_lora,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3eC7_MBCnky"
   },
   "outputs": [],
   "source": [
    "# Train!\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"Done Training LoRA model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9JMHnmbCtTB"
   },
   "source": [
    "# Evaluate & Compare\n",
    "Let's do a quick perplexity check on the validation (or test) set. We'll reuse the Trainer\u2019s `evaluate()` method, which will compute the causal LM loss. Then perplexity = `exp(loss)`. If the perplexity is high the data is improbable; if the perplexity is low, then the data is expected and our models works well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIG2fY7ACwnk"
   },
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n",
    "val_loss = eval_results[\"eval_loss\"]\n",
    "val_ppl = np.exp(val_loss)\n",
    "print(f\"Validation Perplexity: {val_ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOIIBTHiuOS5"
   },
   "source": [
    "# Homework Assignments\n",
    "\n",
    "1. **Adapt an LLM** (e.g., Galactical used above) with LoRA to your text and evaluate its perplexity before and after adaptation.\n",
    "\n",
    "2. **QLoRA**: Load a 4-bit quantized model (via bitsandbytes), apply LoRA, and fine-tune. Compare GPU memory usage, speed, and resulting perplexity with the standard LoRA approach above.\n",
    "\n",
    "3. **Hyperparameter Tuning**: Adjust `r`, `lora_alpha`, `lora_dropout`, or the learning rate.\n",
    "\n",
    "4. **Regularization**: Introduce weight decay, dropout in LoRA layers, or regularization of adapter weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yV8AmTDai6wc"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "module3"
   },
   "source": [
    "# Module 3: Benchmarking LLM Agents\n",
    "\n",
    "Evaluating LLM-based agents requires systematic benchmarking approaches that go beyond traditional metrics. This module covers:\n",
    "\n",
    "1. **Centered Kernel Alignment (CKA)** - A metric for comparing neural network representations\n",
    "2. **Agent Benchmarking Frameworks** - Systematic evaluation of agent capabilities\n",
    "3. **Bias in Benchmarks** - Understanding how benchmark design affects evaluation\n",
    "\n",
    "**Key Readings:**\n",
    "- Kornblith et al. (2019) \"Similarity of Neural Network Representations Revisited\" (CKA)\n",
    "- Mohammadi et al. (2025) \"Evaluation and Benchmarking of LLM Agents: A Survey\"\n",
    "- Kapoor et al. (2024) \"AI Agents That Matter\"\n",
    "- Liu et al. (2024) \"AgentBench: Evaluating LLMs as Agents\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cka_intro"
   },
   "source": [
    "## Part 1: Centered Kernel Alignment (CKA)\n",
    "\n",
    "CKA is a method for comparing representations learned by different neural networks or different layers within the same network. It measures similarity in a way that is:\n",
    "- **Invariant to orthogonal transformations** (e.g., neuron permutation)\n",
    "- **Invariant to isotropic scaling**\n",
    "\n",
    "This makes it particularly useful for understanding:\n",
    "- How representations evolve during training\n",
    "- How different architectures learn similar or different representations\n",
    "- Which layers are most important for specific tasks\n",
    "\n",
    "### Mathematical Foundation\n",
    "\n",
    "The CKA score is defined as:\n",
    "\n",
    "$$\\texttt{CKA}(\\mathbf{K}, \\mathbf{L}) = \\frac{\\texttt{HSIC}(\\mathbf{K}, \\mathbf{L})}{\\sqrt{\\texttt{HSIC}(\\mathbf{K}, \\mathbf{K})\\texttt{HSIC}(\\mathbf{L}, \\mathbf{L})}}$$\n",
    "\n",
    "where HSIC is the Hilbert-Schmidt Independence Criterion:\n",
    "\n",
    "$$\\texttt{HSIC}(\\mathbf{K}, \\mathbf{L}) = \\frac{\\text{tr}(\\mathbf{K} \\mathbf{H}_m \\mathbf{L} \\mathbf{H}_m)}{(m-1)^2}$$\n",
    "\n",
    "with $\\mathbf{H}_m = \\mathbf{I}_m - \\frac{1}{m} \\mathbf{1}\\mathbf{1}^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cka_setup"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cka_imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cka_implementation"
   },
   "outputs": [],
   "source": [
    "def linear_CKA(X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Linear Centered Kernel Alignment between two sets of representations.\n",
    "    \n",
    "    Args:\n",
    "        X: (n_samples, n_features_1) - representations from first source\n",
    "        Y: (n_samples, n_features_2) - representations from second source\n",
    "    \n",
    "    Returns:\n",
    "        CKA similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    # Center the data\n",
    "    X = X - X.mean(axis=0)\n",
    "    Y = Y - Y.mean(axis=0)\n",
    "    \n",
    "    # Compute Gram matrices (linear kernel)\n",
    "    K = X @ X.T\n",
    "    L = Y @ Y.T\n",
    "    \n",
    "    # Compute HSIC\n",
    "    def hsic(K, L):\n",
    "        n = K.shape[0]\n",
    "        H = np.eye(n) - np.ones((n, n)) / n\n",
    "        return np.trace(K @ H @ L @ H) / (n - 1) ** 2\n",
    "    \n",
    "    # Compute CKA\n",
    "    hsic_kl = hsic(K, L)\n",
    "    hsic_kk = hsic(K, K)\n",
    "    hsic_ll = hsic(L, L)\n",
    "    \n",
    "    return hsic_kl / np.sqrt(hsic_kk * hsic_ll)\n",
    "\n",
    "\n",
    "def rbf_CKA(X: np.ndarray, Y: np.ndarray, sigma: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    Compute RBF (Radial Basis Function) CKA between two sets of representations.\n",
    "    \n",
    "    Args:\n",
    "        X: (n_samples, n_features_1) - representations from first source\n",
    "        Y: (n_samples, n_features_2) - representations from second source\n",
    "        sigma: RBF kernel bandwidth\n",
    "    \n",
    "    Returns:\n",
    "        CKA similarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    def rbf_kernel(X, sigma):\n",
    "        # Compute pairwise squared Euclidean distances\n",
    "        sq_dists = np.sum(X**2, axis=1, keepdims=True) + np.sum(X**2, axis=1) - 2 * X @ X.T\n",
    "        return np.exp(-sq_dists / (2 * sigma**2))\n",
    "    \n",
    "    K = rbf_kernel(X, sigma)\n",
    "    L = rbf_kernel(Y, sigma)\n",
    "    \n",
    "    def hsic(K, L):\n",
    "        n = K.shape[0]\n",
    "        H = np.eye(n) - np.ones((n, n)) / n\n",
    "        return np.trace(K @ H @ L @ H) / (n - 1) ** 2\n",
    "    \n",
    "    hsic_kl = hsic(K, L)\n",
    "    hsic_kk = hsic(K, K)\n",
    "    hsic_ll = hsic(L, L)\n",
    "    \n",
    "    return hsic_kl / np.sqrt(hsic_kk * hsic_ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cka_demo"
   },
   "source": [
    "### Demonstration: Comparing Neural Network Layer Representations\n",
    "\n",
    "Let's create a simple example to demonstrate CKA by comparing representations from different layers of a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cka_model"
   },
   "outputs": [],
   "source": [
    "# Define a simple neural network with hooks to capture layer activations\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dims=[256, 128, 64], output_dim=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        dims = [input_dim] + hidden_dims\n",
    "        for i in range(len(dims) - 1):\n",
    "            self.layers.append(nn.Linear(dims[i], dims[i+1]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.output = nn.Linear(hidden_dims[-1], output_dim)\n",
    "        \n",
    "        # Storage for layer activations\n",
    "        self.activations = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.activations = [x.detach().numpy()]  # Store input\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            if isinstance(layer, nn.ReLU):\n",
    "                self.activations.append(x.detach().numpy())\n",
    "        x = self.output(x)\n",
    "        self.activations.append(x.detach().numpy())\n",
    "        return x\n",
    "\n",
    "# Create two networks (simulating different random initializations)\n",
    "torch.manual_seed(42)\n",
    "net1 = SimpleNet()\n",
    "torch.manual_seed(123)\n",
    "net2 = SimpleNet()\n",
    "\n",
    "# Generate random input data\n",
    "X = torch.randn(100, 784)\n",
    "\n",
    "# Get activations from both networks\n",
    "with torch.no_grad():\n",
    "    _ = net1(X)\n",
    "    activations1 = net1.activations.copy()\n",
    "    _ = net2(X)\n",
    "    activations2 = net2.activations.copy()\n",
    "\n",
    "print(f\"Number of layers captured: {len(activations1)}\")\n",
    "for i, act in enumerate(activations1):\n",
    "    print(f\"Layer {i}: shape {act.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cka_matrix"
   },
   "outputs": [],
   "source": [
    "def compute_cka_matrix(activations1: List[np.ndarray], \n",
    "                       activations2: List[np.ndarray]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute pairwise CKA scores between all layers of two networks.\n",
    "    \"\"\"\n",
    "    n1, n2 = len(activations1), len(activations2)\n",
    "    cka_matrix = np.zeros((n1, n2))\n",
    "    \n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            cka_matrix[i, j] = linear_CKA(activations1[i], activations2[j])\n",
    "    \n",
    "    return cka_matrix\n",
    "\n",
    "\n",
    "def plot_cka_matrix(cka_matrix: np.ndarray, \n",
    "                    title: str = \"CKA Similarity Matrix\",\n",
    "                    xlabel: str = \"Network 2 Layers\",\n",
    "                    ylabel: str = \"Network 1 Layers\"):\n",
    "    \"\"\"\n",
    "    Plot a CKA similarity matrix as a heatmap.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    im = ax.imshow(cka_matrix, cmap='viridis', vmin=0, vmax=1)\n",
    "    \n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('CKA Score', fontsize=12)\n",
    "    \n",
    "    # Add layer labels\n",
    "    n1, n2 = cka_matrix.shape\n",
    "    ax.set_xticks(range(n2))\n",
    "    ax.set_yticks(range(n1))\n",
    "    ax.set_xticklabels([f'L{i}' for i in range(n2)])\n",
    "    ax.set_yticklabels([f'L{i}' for i in range(n1)])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Compute and plot CKA matrix for self-similarity\n",
    "cka_self = compute_cka_matrix(activations1, activations1)\n",
    "plot_cka_matrix(cka_self, title=\"Self-Similarity (Same Network)\", \n",
    "                xlabel=\"Layer\", ylabel=\"Layer\")\n",
    "plt.show()\n",
    "\n",
    "# Compute and plot CKA matrix between two networks\n",
    "cka_cross = compute_cka_matrix(activations1, activations2)\n",
    "plot_cka_matrix(cka_cross, title=\"Cross-Network Similarity (Different Seeds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agent_benchmarking"
   },
   "source": [
    "## Part 2: Benchmarking LLM Agents\n",
    "\n",
    "Evaluating LLM-based agents goes beyond simple accuracy metrics. According to Mohammadi et al. (2025) and Kapoor et al. (2024), comprehensive agent evaluation should consider:\n",
    "\n",
    "### Key Evaluation Dimensions\n",
    "\n",
    "1. **Task Completion Rate** - Can the agent complete the assigned task?\n",
    "2. **Efficiency** - How many steps/tokens/API calls does it take?\n",
    "3. **Safety** - Does the agent avoid harmful actions?\n",
    "4. **Robustness** - How well does the agent handle edge cases?\n",
    "5. **Generalization** - Does performance transfer to new domains?\n",
    "\n",
    "### Common Benchmarks\n",
    "\n",
    "| Benchmark | Focus Area | Key Metrics |\n",
    "|-----------|------------|-------------|\n",
    "| AgentBench | General agent capabilities | Success rate, efficiency |\n",
    "| WebArena | Web navigation | Task completion, # actions |\n",
    "| SWE-Bench | Software engineering | Resolved issues % |\n",
    "| ToolBench | Tool use | API call accuracy |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agent_eval_framework"
   },
   "outputs": [],
   "source": [
    "# Simple Agent Evaluation Framework\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, Any, Optional\n",
    "import time\n",
    "\n",
    "@dataclass\n",
    "class BenchmarkTask:\n",
    "    \"\"\"A single benchmark task for agent evaluation.\"\"\"\n",
    "    task_id: str\n",
    "    description: str\n",
    "    input_data: Any\n",
    "    expected_output: Any\n",
    "    max_steps: int = 10\n",
    "    timeout_seconds: float = 60.0\n",
    "\n",
    "@dataclass \n",
    "class EvaluationResult:\n",
    "    \"\"\"Results from evaluating an agent on a task.\"\"\"\n",
    "    task_id: str\n",
    "    success: bool\n",
    "    steps_taken: int\n",
    "    time_elapsed: float\n",
    "    agent_output: Any\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "\n",
    "class AgentBenchmark:\n",
    "    \"\"\"Framework for benchmarking LLM agents.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        self.tasks: List[BenchmarkTask] = []\n",
    "        self.results: List[EvaluationResult] = []\n",
    "    \n",
    "    def add_task(self, task: BenchmarkTask):\n",
    "        \"\"\"Add a task to the benchmark.\"\"\"\n",
    "        self.tasks.append(task)\n",
    "    \n",
    "    def evaluate_agent(self, agent_fn: Callable, \n",
    "                       evaluator_fn: Callable[[Any, Any], bool]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate an agent on all benchmark tasks.\n",
    "        \n",
    "        Args:\n",
    "            agent_fn: Function that takes (input_data) and returns (output, steps)\n",
    "            evaluator_fn: Function that takes (output, expected) and returns bool\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of evaluation metrics\n",
    "        \"\"\"\n",
    "        self.results = []\n",
    "        \n",
    "        for task in self.tasks:\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                output, steps = agent_fn(task.input_data)\n",
    "                elapsed = time.time() - start_time\n",
    "                success = evaluator_fn(output, task.expected_output)\n",
    "                \n",
    "                result = EvaluationResult(\n",
    "                    task_id=task.task_id,\n",
    "                    success=success,\n",
    "                    steps_taken=steps,\n",
    "                    time_elapsed=elapsed,\n",
    "                    agent_output=output\n",
    "                )\n",
    "            except Exception as e:\n",
    "                result = EvaluationResult(\n",
    "                    task_id=task.task_id,\n",
    "                    success=False,\n",
    "                    steps_taken=0,\n",
    "                    time_elapsed=time.time() - start_time,\n",
    "                    agent_output=None,\n",
    "                    error_message=str(e)\n",
    "                )\n",
    "            \n",
    "            self.results.append(result)\n",
    "        \n",
    "        # Compute aggregate metrics\n",
    "        success_rate = sum(r.success for r in self.results) / len(self.results)\n",
    "        avg_steps = np.mean([r.steps_taken for r in self.results if r.success])\n",
    "        avg_time = np.mean([r.time_elapsed for r in self.results])\n",
    "        \n",
    "        return {\n",
    "            'success_rate': success_rate,\n",
    "            'avg_steps_on_success': avg_steps if not np.isnan(avg_steps) else 0,\n",
    "            'avg_time_seconds': avg_time,\n",
    "            'total_tasks': len(self.tasks)\n",
    "        }\n",
    "\n",
    "print(\"Agent Benchmark Framework loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agent_eval_demo"
   },
   "outputs": [],
   "source": [
    "# Example: Simple Math Agent Benchmark\n",
    "\n",
    "# Create a simple benchmark\n",
    "math_benchmark = AgentBenchmark(\"Simple Math\")\n",
    "\n",
    "# Add tasks\n",
    "math_tasks = [\n",
    "    BenchmarkTask(\"add_1\", \"Add two numbers\", (3, 5), 8),\n",
    "    BenchmarkTask(\"add_2\", \"Add two numbers\", (10, 20), 30),\n",
    "    BenchmarkTask(\"multiply_1\", \"Multiply two numbers\", (4, 7), 28),\n",
    "    BenchmarkTask(\"complex_1\", \"Complex calculation\", (2, 3, 4), 14),  # 2*3 + 4 + 4\n",
    "]\n",
    "\n",
    "for task in math_tasks:\n",
    "    math_benchmark.add_task(task)\n",
    "\n",
    "# Define a simple agent\n",
    "def simple_math_agent(input_data):\n",
    "    \"\"\"A simple agent that performs math operations.\"\"\"\n",
    "    steps = 1\n",
    "    if len(input_data) == 2:\n",
    "        # Try addition first, then multiplication\n",
    "        result = input_data[0] + input_data[1]\n",
    "        steps = 1\n",
    "    elif len(input_data) == 3:\n",
    "        result = input_data[0] * input_data[1] + input_data[2] + input_data[2]\n",
    "        steps = 3\n",
    "    else:\n",
    "        result = sum(input_data)\n",
    "        steps = len(input_data)\n",
    "    return result, steps\n",
    "\n",
    "# Define evaluator\n",
    "def exact_match_evaluator(output, expected):\n",
    "    return output == expected\n",
    "\n",
    "# Run evaluation\n",
    "results = math_benchmark.evaluate_agent(simple_math_agent, exact_match_evaluator)\n",
    "\n",
    "print(\"\\n=== Benchmark Results ===\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.2f}\" if isinstance(value, float) else f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n=== Per-Task Results ===\")\n",
    "for result in math_benchmark.results:\n",
    "    status = \"\u2713\" if result.success else \"\u2717\"\n",
    "    print(f\"{status} {result.task_id}: output={result.agent_output}, steps={result.steps_taken}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bias_benchmarks"
   },
   "source": [
    "## Part 3: Bias in Benchmark Design\n",
    "\n",
    "Benchmark design can introduce systematic biases that affect how we evaluate AI agents:\n",
    "\n",
    "### Sources of Bias\n",
    "\n",
    "1. **Selection Bias** - Tasks may not represent real-world distribution\n",
    "2. **Cultural Bias** - Benchmarks often reflect Western, English-centric perspectives\n",
    "3. **Temporal Bias** - Training data contamination (models may have seen test data)\n",
    "4. **Difficulty Calibration** - Task difficulty may not scale appropriately\n",
    "\n",
    "### Mitigation Strategies\n",
    "\n",
    "- Use held-out test sets with temporal splits\n",
    "- Include diverse cultural and linguistic examples\n",
    "- Report confidence intervals, not just point estimates\n",
    "- Use multiple benchmarks to avoid overfitting to one metric\n",
    "\n",
    "### Model Collapse Warning\n",
    "\n",
    "As noted in Shumailov et al. (2024), models trained on recursively generated data can collapse. This has implications for benchmark creation:\n",
    "- Synthetic benchmarks may not capture real-world complexity\n",
    "- Over-reliance on LLM-generated evaluation data can be problematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bias_demo"
   },
   "outputs": [],
   "source": [
    "# Demonstration: How benchmark composition affects reported performance\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate an agent with different performance on different task types\n",
    "np.random.seed(42)\n",
    "\n",
    "# Agent performance on different task categories (success probability)\n",
    "agent_performance = {\n",
    "    'english_text': 0.90,\n",
    "    'multilingual': 0.60,\n",
    "    'math': 0.75,\n",
    "    'code': 0.80,\n",
    "    'reasoning': 0.70\n",
    "}\n",
    "\n",
    "def simulate_benchmark(task_distribution: Dict[str, int], \n",
    "                       performance: Dict[str, float], \n",
    "                       n_runs: int = 100) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Simulate benchmark results given task distribution and agent performance.\n",
    "    \n",
    "    Returns: (mean_success_rate, std_success_rate)\n",
    "    \"\"\"\n",
    "    all_rates = []\n",
    "    \n",
    "    for _ in range(n_runs):\n",
    "        successes = 0\n",
    "        total = 0\n",
    "        \n",
    "        for task_type, count in task_distribution.items():\n",
    "            prob = performance.get(task_type, 0.5)\n",
    "            successes += np.random.binomial(count, prob)\n",
    "            total += count\n",
    "        \n",
    "        all_rates.append(successes / total)\n",
    "    \n",
    "    return np.mean(all_rates), np.std(all_rates)\n",
    "\n",
    "# Define different benchmark compositions\n",
    "benchmarks = {\n",
    "    'English-Heavy': {'english_text': 80, 'multilingual': 5, 'math': 5, 'code': 5, 'reasoning': 5},\n",
    "    'Balanced': {'english_text': 20, 'multilingual': 20, 'math': 20, 'code': 20, 'reasoning': 20},\n",
    "    'Technical': {'english_text': 10, 'multilingual': 10, 'math': 30, 'code': 30, 'reasoning': 20},\n",
    "    'Multilingual': {'english_text': 20, 'multilingual': 60, 'math': 10, 'code': 5, 'reasoning': 5}\n",
    "}\n",
    "\n",
    "# Simulate and plot results\n",
    "results = {}\n",
    "for name, dist in benchmarks.items():\n",
    "    mean, std = simulate_benchmark(dist, agent_performance)\n",
    "    results[name] = (mean, std)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "names = list(results.keys())\n",
    "means = [results[n][0] for n in names]\n",
    "stds = [results[n][1] for n in names]\n",
    "\n",
    "bars = ax.bar(names, means, yerr=stds, capsize=5, color=['#2ecc71', '#3498db', '#9b59b6', '#e74c3c'])\n",
    "ax.set_ylabel('Success Rate', fontsize=12)\n",
    "ax.set_xlabel('Benchmark Type', fontsize=12)\n",
    "ax.set_title('Same Agent, Different Benchmark Compositions', fontsize=14)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axhline(y=0.75, color='gray', linestyle='--', label='\"True\" average performance')\n",
    "ax.legend()\n",
    "\n",
    "for bar, mean in zip(bars, means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.03, \n",
    "            f'{mean:.1%}', ha='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: The SAME agent shows very different 'performance' \")\n",
    "print(\"depending on how the benchmark tasks are composed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "module3_exercises"
   },
   "source": [
    "## Module 3 Exercises\n",
    "\n",
    "### Exercise 1: CKA Analysis\n",
    "Train a simple neural network on MNIST or CIFAR-10, save checkpoints during training, and use CKA to analyze how representations change during training.\n",
    "\n",
    "### Exercise 2: Agent Benchmark Design\n",
    "Design a benchmark for a specific domain (e.g., question answering, code generation). Consider:\n",
    "- What tasks should be included?\n",
    "- What metrics matter most?\n",
    "- How would you ensure the benchmark is fair and unbiased?\n",
    "\n",
    "### Exercise 3: Critical Analysis\n",
    "Read Kapoor et al. (2024) \"AI Agents That Matter\" and write a 1-page summary of:\n",
    "- What makes a benchmark \"good\"?\n",
    "- What are common pitfalls in agent evaluation?\n",
    "- How would you apply these lessons to your research?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "module4"
   },
   "source": [
    "# Module 4: Tools and the Model Context Protocol (MCP)\n",
    "\n",
    "Modern LLM agents extend their capabilities by interacting with external tools, APIs, and data sources. This module covers:\n",
    "\n",
    "1. **Tool Use Patterns** - How LLMs interact with external functions\n",
    "2. **Model Context Protocol (MCP)** - A standardized protocol for providing context to AI models\n",
    "3. **Building Tool-Using Agents** - Practical implementation\n",
    "\n",
    "**Key Readings:**\n",
    "- Anthropic (2024) \"What is the Model Context Protocol (MCP)?\"\n",
    "- Epperson et al. (2025) \"Interactive Debugging and Steering of Multi-Agent AI Systems\"\n",
    "- Khattab et al. (2023) \"DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tool_use_intro"
   },
   "source": [
    "## Part 1: Understanding Tool Use in LLMs\n",
    "\n",
    "Tool use allows LLMs to:\n",
    "- **Access real-time information** (web search, databases)\n",
    "- **Perform calculations** (code execution, math)\n",
    "- **Take actions** (send emails, create files)\n",
    "- **Interact with external services** (APIs, cloud services)\n",
    "\n",
    "### Tool Use Architecture\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502   User      \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   LLM       \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Tool      \u2502\n",
    "\u2502   Request   \u2502     \u2502   Agent     \u2502     \u2502   Executor  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                           \u2502                   \u2502\n",
    "                           \u25bc                   \u25bc\n",
    "                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "                    \u2502   Tool      \u2502     \u2502   External  \u2502\n",
    "                    \u2502   Selection \u2502     \u2502   Service   \u2502\n",
    "                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "1. **Tool Definition** - JSON schema describing the tool's interface\n",
    "2. **Tool Selection** - LLM decides which tool(s) to use\n",
    "3. **Parameter Extraction** - LLM extracts arguments from user request\n",
    "4. **Result Integration** - Tool output is fed back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tool_setup"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install openai anthropic requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tool_framework"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Callable, Dict, Any, List\n",
    "from dataclasses import dataclass, field\n",
    "import inspect\n",
    "\n",
    "@dataclass\n",
    "class Tool:\n",
    "    \"\"\"Represents a tool that an LLM can use.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    parameters: Dict[str, Any]\n",
    "    function: Callable\n",
    "    \n",
    "    def to_schema(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to OpenAI/Anthropic tool schema format.\"\"\"\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parameters\": self.parameters\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def execute(self, **kwargs) -> Any:\n",
    "        \"\"\"Execute the tool with given arguments.\"\"\"\n",
    "        return self.function(**kwargs)\n",
    "\n",
    "\n",
    "class ToolRegistry:\n",
    "    \"\"\"Registry for managing available tools.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str, Tool] = {}\n",
    "    \n",
    "    def register(self, tool: Tool):\n",
    "        \"\"\"Register a new tool.\"\"\"\n",
    "        self.tools[tool.name] = tool\n",
    "    \n",
    "    def get(self, name: str) -> Tool:\n",
    "        \"\"\"Get a tool by name.\"\"\"\n",
    "        return self.tools.get(name)\n",
    "    \n",
    "    def list_schemas(self) -> List[Dict]:\n",
    "        \"\"\"Get schemas for all registered tools.\"\"\"\n",
    "        return [tool.to_schema() for tool in self.tools.values()]\n",
    "    \n",
    "    def execute(self, name: str, **kwargs) -> Any:\n",
    "        \"\"\"Execute a tool by name.\"\"\"\n",
    "        tool = self.get(name)\n",
    "        if tool is None:\n",
    "            raise ValueError(f\"Tool '{name}' not found\")\n",
    "        return tool.execute(**kwargs)\n",
    "\n",
    "print(\"Tool framework loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "example_tools"
   },
   "outputs": [],
   "source": [
    "# Define example tools\n",
    "\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
    "    try:\n",
    "        # Simple and safe evaluation (for demo only)\n",
    "        allowed_chars = set('0123456789+-*/().^ ')\n",
    "        if not all(c in allowed_chars for c in expression):\n",
    "            return \"Error: Invalid characters in expression\"\n",
    "        result = eval(expression.replace('^', '**'))\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get current weather for a city (simulated).\"\"\"\n",
    "    # Simulated weather data\n",
    "    import random\n",
    "    random.seed(hash(city) % 100)\n",
    "    temp = random.randint(40, 90)\n",
    "    conditions = random.choice(['Sunny', 'Cloudy', 'Rainy', 'Partly Cloudy'])\n",
    "    return f\"Weather in {city}: {temp}\u00b0F, {conditions}\"\n",
    "\n",
    "def search_database(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search a database (simulated).\"\"\"\n",
    "    # Simulated database results\n",
    "    results = [\n",
    "        f\"Result {i+1}: Document about '{query}' - relevance: {0.9 - i*0.1:.1f}\"\n",
    "        for i in range(limit)\n",
    "    ]\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# Create tool registry and register tools\n",
    "registry = ToolRegistry()\n",
    "\n",
    "registry.register(Tool(\n",
    "    name=\"calculator\",\n",
    "    description=\"Evaluate mathematical expressions. Use for any calculations.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"expression\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Mathematical expression to evaluate (e.g., '2 + 2', '3 * 4')\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"expression\"]\n",
    "    },\n",
    "    function=calculator\n",
    "))\n",
    "\n",
    "registry.register(Tool(\n",
    "    name=\"get_weather\",\n",
    "    description=\"Get the current weather for a specified city.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the city (e.g., 'New York', 'London')\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"city\"]\n",
    "    },\n",
    "    function=get_weather\n",
    "))\n",
    "\n",
    "registry.register(Tool(\n",
    "    name=\"search_database\",\n",
    "    description=\"Search a database for relevant documents.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Maximum number of results (default: 5)\",\n",
    "                \"default\": 5\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    },\n",
    "    function=search_database\n",
    "))\n",
    "\n",
    "# Display registered tools\n",
    "print(\"Registered Tools:\")\n",
    "print(json.dumps(registry.list_schemas(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tool_demo"
   },
   "outputs": [],
   "source": [
    "# Demonstrate tool execution\n",
    "\n",
    "print(\"=== Calculator Tool ===\")\n",
    "print(registry.execute(\"calculator\", expression=\"2 + 2 * 3\"))\n",
    "print(registry.execute(\"calculator\", expression=\"(10 + 5) ^ 2\"))\n",
    "\n",
    "print(\"\\n=== Weather Tool ===\")\n",
    "print(registry.execute(\"get_weather\", city=\"Chicago\"))\n",
    "print(registry.execute(\"get_weather\", city=\"San Francisco\"))\n",
    "\n",
    "print(\"\\n=== Database Search Tool ===\")\n",
    "print(registry.execute(\"search_database\", query=\"machine learning\", limit=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcp_intro"
   },
   "source": [
    "## Part 2: Model Context Protocol (MCP)\n",
    "\n",
    "The **Model Context Protocol (MCP)** is an open standard developed by Anthropic that enables AI models to securely access data from various sources. MCP provides a standardized way for LLMs to:\n",
    "\n",
    "1. **Access local files and databases**\n",
    "2. **Query external APIs and services**\n",
    "3. **Interact with development tools**\n",
    "4. **Maintain context across sessions**\n",
    "\n",
    "### MCP Architecture\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502                    MCP Host                         \u2502\n",
    "\u2502  (Claude Desktop, IDE, or Custom Application)      \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "                        \u2502 MCP Protocol\n",
    "        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "        \u25bc               \u25bc               \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502  MCP Server  \u2502 \u2502  MCP Server  \u2502 \u2502  MCP Server  \u2502\n",
    "\u2502  (Files)     \u2502 \u2502  (Database)  \u2502 \u2502  (API)       \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "        \u2502               \u2502               \u2502\n",
    "        \u25bc               \u25bc               \u25bc\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502 Local Files  \u2502 \u2502  PostgreSQL  \u2502 \u2502  REST API   \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **MCP Host** - The application hosting the AI model (e.g., Claude Desktop)\n",
    "2. **MCP Server** - Provides access to a specific data source or capability\n",
    "3. **MCP Protocol** - JSON-RPC based communication protocol\n",
    "\n",
    "### Server Capabilities\n",
    "\n",
    "MCP servers can expose:\n",
    "- **Resources** - File-like data (documents, images, etc.)\n",
    "- **Tools** - Functions the AI can call\n",
    "- **Prompts** - Template prompts for specific tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcp_server"
   },
   "outputs": [],
   "source": [
    "# Simple MCP Server Implementation (Conceptual)\n",
    "\n",
    "import json\n",
    "from typing import Dict, Any, List, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "@dataclass\n",
    "class MCPResource:\n",
    "    \"\"\"Represents a resource exposed by an MCP server.\"\"\"\n",
    "    uri: str\n",
    "    name: str\n",
    "    description: str\n",
    "    mime_type: str = \"text/plain\"\n",
    "\n",
    "@dataclass\n",
    "class MCPTool:\n",
    "    \"\"\"Represents a tool exposed by an MCP server.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    input_schema: Dict[str, Any]\n",
    "\n",
    "\n",
    "class MCPServer(ABC):\n",
    "    \"\"\"Base class for MCP servers.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, version: str = \"1.0.0\"):\n",
    "        self.name = name\n",
    "        self.version = version\n",
    "        self._resources: Dict[str, MCPResource] = {}\n",
    "        self._tools: Dict[str, MCPTool] = {}\n",
    "    \n",
    "    def get_server_info(self) -> Dict[str, Any]:\n",
    "        \"\"\"Return server information.\"\"\"\n",
    "        return {\n",
    "            \"name\": self.name,\n",
    "            \"version\": self.version,\n",
    "            \"protocolVersion\": \"2024-11-05\"\n",
    "        }\n",
    "    \n",
    "    def list_resources(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"List available resources.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"uri\": r.uri,\n",
    "                \"name\": r.name,\n",
    "                \"description\": r.description,\n",
    "                \"mimeType\": r.mime_type\n",
    "            }\n",
    "            for r in self._resources.values()\n",
    "        ]\n",
    "    \n",
    "    def list_tools(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"List available tools.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"name\": t.name,\n",
    "                \"description\": t.description,\n",
    "                \"inputSchema\": t.input_schema\n",
    "            }\n",
    "            for t in self._tools.values()\n",
    "        ]\n",
    "    \n",
    "    @abstractmethod\n",
    "    def read_resource(self, uri: str) -> str:\n",
    "        \"\"\"Read a resource by URI.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def call_tool(self, name: str, arguments: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Call a tool with given arguments.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "print(\"MCP Server base class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcp_example"
   },
   "outputs": [],
   "source": [
    "# Example: Research Data MCP Server\n",
    "\n",
    "class ResearchDataServer(MCPServer):\n",
    "    \"\"\"MCP server that exposes research datasets and analysis tools.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"research-data-server\")\n",
    "        \n",
    "        # Simulated research datasets\n",
    "        self._datasets = {\n",
    "            \"dataset://surveys/2024\": {\n",
    "                \"name\": \"Public Opinion Survey 2024\",\n",
    "                \"records\": 1500,\n",
    "                \"columns\": [\"age\", \"gender\", \"opinion_score\", \"region\"]\n",
    "            },\n",
    "            \"dataset://experiments/llm-bias\": {\n",
    "                \"name\": \"LLM Bias Study Results\",\n",
    "                \"records\": 500,\n",
    "                \"columns\": [\"model\", \"prompt_type\", \"bias_score\", \"confidence\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Register resources\n",
    "        for uri, data in self._datasets.items():\n",
    "            self._resources[uri] = MCPResource(\n",
    "                uri=uri,\n",
    "                name=data[\"name\"],\n",
    "                description=f\"Dataset with {data['records']} records\",\n",
    "                mime_type=\"application/json\"\n",
    "            )\n",
    "        \n",
    "        # Register tools\n",
    "        self._tools[\"summarize_dataset\"] = MCPTool(\n",
    "            name=\"summarize_dataset\",\n",
    "            description=\"Get summary statistics for a dataset\",\n",
    "            input_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"dataset_uri\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"dataset_uri\"]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self._tools[\"run_analysis\"] = MCPTool(\n",
    "            name=\"run_analysis\",\n",
    "            description=\"Run statistical analysis on a dataset\",\n",
    "            input_schema={\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"dataset_uri\": {\"type\": \"string\"},\n",
    "                    \"analysis_type\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"correlation\", \"regression\", \"ttest\"]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"dataset_uri\", \"analysis_type\"]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def read_resource(self, uri: str) -> str:\n",
    "        \"\"\"Read a dataset resource.\"\"\"\n",
    "        if uri not in self._datasets:\n",
    "            raise ValueError(f\"Resource not found: {uri}\")\n",
    "        return json.dumps(self._datasets[uri], indent=2)\n",
    "    \n",
    "    def call_tool(self, name: str, arguments: Dict[str, Any]) -> Any:\n",
    "        \"\"\"Call an analysis tool.\"\"\"\n",
    "        if name == \"summarize_dataset\":\n",
    "            uri = arguments[\"dataset_uri\"]\n",
    "            if uri not in self._datasets:\n",
    "                return {\"error\": f\"Dataset not found: {uri}\"}\n",
    "            data = self._datasets[uri]\n",
    "            return {\n",
    "                \"name\": data[\"name\"],\n",
    "                \"total_records\": data[\"records\"],\n",
    "                \"columns\": data[\"columns\"],\n",
    "                \"summary\": f\"Dataset contains {data['records']} records across {len(data['columns'])} variables\"\n",
    "            }\n",
    "        \n",
    "        elif name == \"run_analysis\":\n",
    "            uri = arguments[\"dataset_uri\"]\n",
    "            analysis = arguments[\"analysis_type\"]\n",
    "            # Simulated analysis results\n",
    "            return {\n",
    "                \"analysis_type\": analysis,\n",
    "                \"dataset\": uri,\n",
    "                \"result\": f\"Simulated {analysis} analysis completed\",\n",
    "                \"statistics\": {\n",
    "                    \"p_value\": 0.03,\n",
    "                    \"effect_size\": 0.45\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        return {\"error\": f\"Unknown tool: {name}\"}\n",
    "\n",
    "\n",
    "# Create and test the server\n",
    "research_server = ResearchDataServer()\n",
    "\n",
    "print(\"=== Server Info ===\")\n",
    "print(json.dumps(research_server.get_server_info(), indent=2))\n",
    "\n",
    "print(\"\\n=== Available Resources ===\")\n",
    "print(json.dumps(research_server.list_resources(), indent=2))\n",
    "\n",
    "print(\"\\n=== Available Tools ===\")\n",
    "print(json.dumps(research_server.list_tools(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcp_usage"
   },
   "outputs": [],
   "source": [
    "# Using the MCP Server\n",
    "\n",
    "print(\"=== Reading a Resource ===\")\n",
    "resource_data = research_server.read_resource(\"dataset://surveys/2024\")\n",
    "print(resource_data)\n",
    "\n",
    "print(\"\\n=== Calling summarize_dataset Tool ===\")\n",
    "summary = research_server.call_tool(\"summarize_dataset\", {\n",
    "    \"dataset_uri\": \"dataset://experiments/llm-bias\"\n",
    "})\n",
    "print(json.dumps(summary, indent=2))\n",
    "\n",
    "print(\"\\n=== Running Analysis ===\")\n",
    "analysis = research_server.call_tool(\"run_analysis\", {\n",
    "    \"dataset_uri\": \"dataset://surveys/2024\",\n",
    "    \"analysis_type\": \"correlation\"\n",
    "})\n",
    "print(json.dumps(analysis, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tool_safety"
   },
   "source": [
    "## Part 3: Tool Use Safety and Best Practices\n",
    "\n",
    "When enabling LLMs to use tools, safety considerations are crucial:\n",
    "\n",
    "### Security Considerations\n",
    "\n",
    "1. **Input Validation** - Always validate tool inputs before execution\n",
    "2. **Sandboxing** - Run tools in isolated environments\n",
    "3. **Rate Limiting** - Prevent abuse through excessive tool calls\n",
    "4. **Audit Logging** - Log all tool invocations for review\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Principle of Least Privilege** - Only expose necessary tools\n",
    "2. **Clear Documentation** - Provide detailed tool descriptions\n",
    "3. **Error Handling** - Return informative error messages\n",
    "4. **Human-in-the-Loop** - Require approval for sensitive operations\n",
    "\n",
    "### Common Pitfalls\n",
    "\n",
    "- **Prompt Injection** - Malicious inputs that manipulate tool behavior\n",
    "- **Information Leakage** - Tools exposing sensitive data\n",
    "- **Infinite Loops** - Agents calling tools recursively\n",
    "- **Resource Exhaustion** - Tools consuming excessive compute/memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "safe_tool_wrapper"
   },
   "outputs": [],
   "source": [
    "# Safe Tool Wrapper with Logging and Validation\n",
    "\n",
    "from datetime import datetime\n",
    "from functools import wraps\n",
    "import re\n",
    "\n",
    "class SafeToolWrapper:\n",
    "    \"\"\"Wrapper that adds safety features to tool execution.\"\"\"\n",
    "    \n",
    "    def __init__(self, tool: Tool, \n",
    "                 max_calls_per_minute: int = 10,\n",
    "                 require_approval: bool = False):\n",
    "        self.tool = tool\n",
    "        self.max_calls = max_calls_per_minute\n",
    "        self.require_approval = require_approval\n",
    "        self.call_history: List[datetime] = []\n",
    "        self.audit_log: List[Dict] = []\n",
    "    \n",
    "    def _check_rate_limit(self) -> bool:\n",
    "        \"\"\"Check if we're within rate limits.\"\"\"\n",
    "        now = datetime.now()\n",
    "        # Remove calls older than 1 minute\n",
    "        self.call_history = [\n",
    "            t for t in self.call_history \n",
    "            if (now - t).seconds < 60\n",
    "        ]\n",
    "        return len(self.call_history) < self.max_calls\n",
    "    \n",
    "    def _validate_input(self, kwargs: Dict) -> bool:\n",
    "        \"\"\"Basic input validation.\"\"\"\n",
    "        for key, value in kwargs.items():\n",
    "            if isinstance(value, str):\n",
    "                # Check for potential injection patterns\n",
    "                dangerous_patterns = [\n",
    "                    r'__[a-z]+__',  # Python dunders\n",
    "                    r'import\\s+',   # Import statements\n",
    "                    r'eval\\s*\\(',   # Eval calls\n",
    "                    r'exec\\s*\\('    # Exec calls\n",
    "                ]\n",
    "                for pattern in dangerous_patterns:\n",
    "                    if re.search(pattern, value, re.IGNORECASE):\n",
    "                        return False\n",
    "        return True\n",
    "    \n",
    "    def execute(self, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Safely execute the tool.\"\"\"\n",
    "        timestamp = datetime.now()\n",
    "        \n",
    "        # Check rate limit\n",
    "        if not self._check_rate_limit():\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Rate limit exceeded. Try again later.\"\n",
    "            }\n",
    "        \n",
    "        # Validate input\n",
    "        if not self._validate_input(kwargs):\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"Input validation failed. Potentially unsafe input detected.\"\n",
    "            }\n",
    "        \n",
    "        # Check approval if required\n",
    "        if self.require_approval:\n",
    "            # In a real system, this would prompt for human approval\n",
    "            print(f\"[APPROVAL REQUIRED] Tool: {self.tool.name}, Args: {kwargs}\")\n",
    "        \n",
    "        # Execute the tool\n",
    "        try:\n",
    "            result = self.tool.execute(**kwargs)\n",
    "            success = True\n",
    "            error = None\n",
    "        except Exception as e:\n",
    "            result = None\n",
    "            success = False\n",
    "            error = str(e)\n",
    "        \n",
    "        # Log the call\n",
    "        self.call_history.append(timestamp)\n",
    "        self.audit_log.append({\n",
    "            \"timestamp\": timestamp.isoformat(),\n",
    "            \"tool\": self.tool.name,\n",
    "            \"arguments\": kwargs,\n",
    "            \"success\": success,\n",
    "            \"error\": error\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"success\": success,\n",
    "            \"result\": result,\n",
    "            \"error\": error\n",
    "        }\n",
    "\n",
    "\n",
    "# Wrap the calculator tool with safety features\n",
    "safe_calculator = SafeToolWrapper(\n",
    "    registry.get(\"calculator\"),\n",
    "    max_calls_per_minute=5\n",
    ")\n",
    "\n",
    "# Test normal usage\n",
    "print(\"Normal calculation:\")\n",
    "print(safe_calculator.execute(expression=\"2 + 2\"))\n",
    "\n",
    "# Test potentially unsafe input\n",
    "print(\"\\nPotentially unsafe input:\")\n",
    "print(safe_calculator.execute(expression=\"__import__('os').system('ls')\"))\n",
    "\n",
    "# View audit log\n",
    "print(\"\\nAudit Log:\")\n",
    "for entry in safe_calculator.audit_log:\n",
    "    print(json.dumps(entry, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "module4_exercises"
   },
   "source": [
    "## Module 4 Exercises\n",
    "\n",
    "### Exercise 1: Build a Tool-Using Agent\n",
    "Create a simple agent that can:\n",
    "- Accept natural language queries\n",
    "- Decide which tool(s) to use\n",
    "- Execute the tools and return results\n",
    "\n",
    "You can use OpenAI, Anthropic, or any LLM API for the agent logic.\n",
    "\n",
    "### Exercise 2: Implement an MCP Server\n",
    "Build an MCP server that exposes:\n",
    "- A resource (e.g., a research dataset or document collection)\n",
    "- At least one tool (e.g., search, summarize, analyze)\n",
    "\n",
    "Test the server with simulated MCP client requests.\n",
    "\n",
    "### Exercise 3: Safety Analysis\n",
    "For a tool of your choice, analyze:\n",
    "- What could go wrong if the tool is misused?\n",
    "- What safety measures would you implement?\n",
    "- How would you test that the safety measures work?\n",
    "\n",
    "Write a 1-page report on your analysis.\n",
    "\n",
    "### Exercise 4: DSPy Pipeline (Advanced)\n",
    "Using the DSPy framework (Khattab et al. 2023), create a pipeline that:\n",
    "- Takes a research question as input\n",
    "- Uses tools to gather relevant information\n",
    "- Synthesizes a response\n",
    "\n",
    "Compare the performance of manually-crafted prompts vs. DSPy-optimized prompts."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}